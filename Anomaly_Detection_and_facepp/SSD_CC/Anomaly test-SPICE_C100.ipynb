{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import faiss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models import SupResNet, SSLResNet\n",
    "from utils3 import (\n",
    "    get_features,\n",
    "    get_features_adv_prob,\n",
    "    get_features_adv,\n",
    "    get_roc_sklearn,\n",
    "    get_pr_sklearn,\n",
    "    get_fpr,\n",
    "    get_outliers,\n",
    "    get_scores_one_cluster,\n",
    ")\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local utils for SSD evaluation\n",
    "def get_scores(ftrain, ftest, food, labelstrain, args):\n",
    "    if args.clusters == 1:\n",
    "        return get_scores_one_cluster(ftrain, ftest, food)\n",
    "    else:\n",
    "        if args.training_mode == \"SupCE\":\n",
    "            print(\"Using data labels as cluster since model is cross-entropy\")\n",
    "            ypred = labelstrain\n",
    "        else:\n",
    "            ypred = get_clusters(ftrain, args.clusters)\n",
    "        return get_scores_multi_cluster(ftrain, ftest, food, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(ftrain, nclusters):\n",
    "    kmeans = faiss.Kmeans(\n",
    "        ftrain.shape[1], nclusters, niter=100, verbose=False, gpu=False\n",
    "    )\n",
    "    kmeans.train(np.random.permutation(ftrain))\n",
    "    _, ypred = kmeans.assign(ftrain)\n",
    "    return ypred\n",
    "\n",
    "\n",
    "def get_scores_multi_cluster(ftrain, ftest, food, ypred):\n",
    "    xc = [ftrain[ypred == i] for i in np.unique(ypred)]\n",
    "\n",
    "    din = [\n",
    "        np.sum(\n",
    "            (ftest - np.mean(x, axis=0, keepdims=True))\n",
    "            * (\n",
    "                np.linalg.pinv(np.cov(x.T, bias=True)).dot(\n",
    "                    (ftest - np.mean(x, axis=0, keepdims=True)).T\n",
    "                )\n",
    "            ).T,\n",
    "            axis=-1,\n",
    "        )\n",
    "        for x in xc\n",
    "    ]\n",
    "    dood = [\n",
    "        np.sum(\n",
    "            (food - np.mean(x, axis=0, keepdims=True))\n",
    "            * (\n",
    "                np.linalg.pinv(np.cov(x.T, bias=True)).dot(\n",
    "                    (food - np.mean(x, axis=0, keepdims=True)).T\n",
    "                )\n",
    "            ).T,\n",
    "            axis=-1,\n",
    "        )\n",
    "        for x in xc\n",
    "    ]\n",
    "\n",
    "    din = np.min(din, axis=0)\n",
    "    dood = np.min(dood, axis=0)\n",
    "\n",
    "    return din, dood\n",
    "\n",
    "\n",
    "def get_eval_results(ftrain, ftest, food, labelstrain, args):\n",
    "    \"\"\"\n",
    "    None.\n",
    "    \"\"\"\n",
    "    print(food)\n",
    "    print(food.shape)\n",
    "    # standardize data\n",
    "    ftrain /= np.linalg.norm(ftrain, axis=-1, keepdims=True) + 1e-10\n",
    "    ftest /= np.linalg.norm(ftest, axis=-1, keepdims=True) + 1e-10\n",
    "    food /= np.linalg.norm(food, axis=-1, keepdims=True) + 1e-10\n",
    "\n",
    "    m, s = np.mean(ftrain, axis=0, keepdims=True), np.std(ftrain, axis=0, keepdims=True)\n",
    "\n",
    "    ftrain = (ftrain - m) / (s + 1e-10)\n",
    "    ftest = (ftest - m) / (s + 1e-10)\n",
    "    food = (food - m) / (s + 1e-10)\n",
    "\n",
    "    dtest, dood = get_scores(ftrain, ftest, food, labelstrain, args)\n",
    "\n",
    "    fpr95 = get_fpr(dtest, dood)\n",
    "    auroc, aupr = get_roc_sklearn(dtest, dood), get_pr_sklearn(dtest, dood)\n",
    "    return fpr95, auroc, aupr\n",
    "\n",
    "def get_eval_results_adv(ftrain, ftest, food, labelstrain, args):\n",
    "    \"\"\"\n",
    "    None.\n",
    "    \"\"\"\n",
    "    print(food)\n",
    "    print(food.shape)\n",
    "    # standardize data\n",
    "    ftrain /= np.linalg.norm(ftrain, axis=-1, keepdims=True) + 1e-10\n",
    "    ftest /= np.linalg.norm(ftest, axis=-1, keepdims=True) + 1e-10\n",
    "    food /= np.linalg.norm(food, axis=-1, keepdims=True) + 1e-10\n",
    "\n",
    "    m, s = np.mean(ftrain, axis=0, keepdims=True), np.std(ftrain, axis=0, keepdims=True)\n",
    "\n",
    "    ftrain = (ftrain - m) / (s + 1e-10)\n",
    "    ftest = (ftest - m) / (s + 1e-10)\n",
    "    food = (food - m) / (s + 1e-10)\n",
    "\n",
    "    dtest, dood = get_scores(ftrain, ftest, food, labelstrain, args)\n",
    "\n",
    "    fpr95 = get_fpr(dtest, dood)\n",
    "    yo = get_outliers(dtest, dood, percentile=95)\n",
    "    auroc, aupr = get_roc_sklearn(dtest, dood), get_pr_sklearn(dtest, dood)\n",
    "    return fpr95, auroc, aupr, dood, dtest, yo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SSD evaluation\")\n",
    "\n",
    "parser.add_argument(\"--exp-name\", type=str, default=\"temp_eval_ssd\")\n",
    "parser.add_argument(\n",
    "\"--training-mode\", type=str,default=\"SimCLR\", choices=(\"SimCLR\", \"SupCon\", \"SupCE\")\n",
    ")\n",
    "parser.add_argument(\"--results-dir\", type=str, default=\"./eval_results\")\n",
    "\n",
    "parser.add_argument(\"--arch\", type=str, default=\"resnet18\")\n",
    "parser.add_argument(\"--classes\", type=int, default=10)\n",
    "parser.add_argument(\"--clusters\", type=int, default=1)\n",
    "\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"cifar100\")\n",
    "parser.add_argument(\n",
    "\"--data-dir\", type=str, default=\"datasets/\"\n",
    ")\n",
    "parser.add_argument(\n",
    "\"--data-mode\", type=str, choices=(\"org\", \"base\", \"ssl\"), default=\"base\"\n",
    ")\n",
    "parser.add_argument(\"--normalize\", action=\"store_true\", default=True)\n",
    "parser.add_argument(\"--batch-size\", type=int, default=256)\n",
    "parser.add_argument(\"--size\", type=int, default=32)\n",
    "\n",
    "parser.add_argument(\"--gpu\", type=str, default=\"0\")\n",
    "parser.add_argument(\"--ckpt\", type=str, help=\"checkpoint path\")\n",
    "parser.add_argument(\"--seed\", type=int, default=12345)\n",
    "\n",
    "args = parser.parse_args([])\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.ckpt= \"./saves/c100r18/1--dataset-cifar100-arch-resnet18-lr-0.5_epochs-500/checkpoint/checkpoint_500.pth.tar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(args.results_dir):\n",
    "        os.mkdir(args.results_dir)\n",
    "\n",
    "results_file = os.path.join(args.results_dir, args.exp_name + \"_ssd.txt\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(logging.FileHandler(results_file, \"a\"))\n",
    "logger.info(args)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "if args.training_mode in [\"SimCLR\", \"SupCon\"]:\n",
    "    model = SSLResNet(arch=args.arch).eval()\n",
    "elif args.training_mode == \"SupCE\":\n",
    "    model = SupResNet(arch=args.arch, num_classes=args.classes).eval()\n",
    "else:\n",
    "    raise ValueError(\"Provide model class\")\n",
    "model.encoder = nn.DataParallel(model.encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint\n",
    "ckpt_dict = torch.load(args.ckpt, map_location=\"cpu\")\n",
    "if \"model\" in ckpt_dict.keys():\n",
    "    ckpt_dict = ckpt_dict[\"model\"]\n",
    "if \"state_dict\" in ckpt_dict.keys():\n",
    "    ckpt_dict = ckpt_dict[\"state_dict\"]\n",
    "model.load_state_dict(ckpt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "train_loader, test_loader, norm_layer = data.__dict__[args.dataset](\n",
    "    args.data_dir,\n",
    "    args.batch_size,\n",
    "    mode=args.data_mode,\n",
    "    normalize=args.normalize,\n",
    "    size=args.size,\n",
    ")\n",
    "\n",
    "features_train, labels_train = get_features(\n",
    "    model.encoder, train_loader\n",
    ")  # using feature befor MLP-head\n",
    "features_test, _ = get_features(model.encoder, test_loader)\n",
    "print(\"In-distribution features shape: \", features_train.shape, features_test.shape)\n",
    "\n",
    "ds = [\"cifar10\", \"cifar100\", \"stl\"]\n",
    "# ds.remove(args.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "\n",
    "gen_input_nc = 3\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = '../../Generator_Models/CIFAR100/netG_SPICE_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, 3).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in ds:\n",
    "d = 'cifar100'\n",
    "_, ood_loader, _ = data.__dict__[d](\n",
    "    args.data_dir,\n",
    "    args.batch_size,\n",
    "    mode=\"base\",\n",
    "    normalize=args.normalize,\n",
    "    norm_layer=norm_layer,\n",
    "    size=args.size,\n",
    ")\n",
    "features_ood, _ = get_features(model.encoder, ood_loader)\n",
    "#     features_ood, _ = get_features_adv(model.encoder, ood_loader, pretrained_G)\n",
    "print(\"Out-of-distribution features shape: \", features_ood.shape)\n",
    "\n",
    "fpr95, auroc, aupr = get_eval_results(\n",
    "    np.copy(features_train),\n",
    "    np.copy(features_test),\n",
    "    np.copy(features_ood),\n",
    "    np.copy(labels_train),\n",
    "    args,\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"In-data = {args.dataset}, OOD = {d}, Clusters = {args.clusters}, FPR95 = {fpr95}, AUROC = {auroc}, AUPR = {aupr}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 'cifar100'\n",
    "_, ood_loader, _ = data.__dict__[d](\n",
    "    args.data_dir,\n",
    "    args.batch_size,\n",
    "    mode=\"base\",\n",
    "    normalize=args.normalize,\n",
    "    norm_layer=norm_layer,\n",
    "    size=args.size,\n",
    ")\n",
    "#     features_ood, _ = get_features(model.encoder, ood_loader)\n",
    "features_ood, _ = get_features_adv(model.encoder, ood_loader, pretrained_G)\n",
    "print(\"Out-of-distribution features shape: \", features_ood.shape)\n",
    "\n",
    "fpr95, auroc, aupr = get_eval_results(\n",
    "    np.copy(features_train),\n",
    "    np.copy(features_test),\n",
    "    np.copy(features_ood),\n",
    "    np.copy(labels_train),\n",
    "    args,\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"In-data = {args.dataset}, OOD = {d}, Clusters = {args.clusters}, FPR95 = {fpr95}, AUROC = {auroc}, AUPR = {aupr}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 'cifar100'\n",
    "_, ood_loader, _ = data.__dict__[d](\n",
    "    args.data_dir,\n",
    "    args.batch_size,\n",
    "    \n",
    "    mode=\"base\",\n",
    "    normalize=args.normalize,\n",
    "    norm_layer=norm_layer,\n",
    "    size=args.size,\n",
    ")\n",
    "#     features_ood, _ = get_features(model.encoder, ood_loader)\n",
    "features_ood, labels_ood = get_features(model.encoder, ood_loader)\n",
    "print(\"Out-of-distribution features shape: \", features_ood.shape)\n",
    "\n",
    "fpr95, auroc, aupr, dood, dtest, yo = get_eval_results_adv(\n",
    "    np.copy(features_train),\n",
    "    np.copy(features_test),\n",
    "    np.copy(features_ood),\n",
    "    np.copy(labels_train),\n",
    "    args,\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"In-data = {args.dataset}, OOD = {d}, Clusters = {args.clusters}, FPR95 = {fpr95}, AUROC = {auroc}, AUPR = {aupr}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(10000) ,dood)\n",
    "plt.plot(range(10000) ,dtest)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 'cifar100'\n",
    "_, ood_loader, _ = data.__dict__[d](\n",
    "    args.data_dir,\n",
    "    args.batch_size,\n",
    "    \n",
    "    mode=\"base\",\n",
    "    normalize=args.normalize,\n",
    "    norm_layer=norm_layer,\n",
    "    size=args.size,\n",
    ")\n",
    "#     features_ood, _ = get_features(model.encoder, ood_loader)\n",
    "features_ood, labels_ood ,imgc, ad_index, dl2  = get_features_adv_prob(model.encoder, ood_loader, pretrained_G, clamp=0.17)\n",
    "print(\"Out-of-distribution features shape: \", features_ood.shape)\n",
    "\n",
    "fpr95, auroc, aupr, dood, dtest, yo = get_eval_results_adv(\n",
    "    np.copy(features_train),\n",
    "    np.copy(features_test),\n",
    "    np.copy(features_ood),\n",
    "    np.copy(labels_train),\n",
    "    args,\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"In-data = {args.dataset}, OOD = {d}, Clusters = {args.clusters}, FPR95 = {fpr95}, AUROC = {auroc}, AUPR = {aupr}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(10000) ,dood, color=\"tab:red\", label=\"Adversarial Distribution\", linewidth=2)\n",
    "plt.plot(range(10000) ,dtest, color=\"tab:blue\", label=\"Original Distribution\", linewidth=2)\n",
    "\n",
    "plt.margins(0)\n",
    "plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='off')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "plt.ylabel('Feature Values', fontsize= 15)\n",
    "plt.xlabel('Sample Id', fontsize= 15)\n",
    "plt.legend(fontsize= 15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('Anomaly_C100_SPICE.pdf', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(ad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "co = 0\n",
    "for j in ad_index:\n",
    "    if yo[j] == 1:\n",
    "        co += 1\n",
    "print(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#averae of 10 runs\n",
    "avg_l = []\n",
    "\n",
    "avg_co = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    d = 'cifar100'\n",
    "    _, ood_loader, _ = data.__dict__[d](\n",
    "        args.data_dir,\n",
    "        args.batch_size,\n",
    "\n",
    "        mode=\"base\",\n",
    "        normalize=args.normalize,\n",
    "        norm_layer=norm_layer,\n",
    "        size=args.size,\n",
    "    )\n",
    "    #     features_ood, _ = get_features(model.encoder, ood_loader)\n",
    "    features_ood, labels_ood ,imgc, ad_index, dl2  = get_features_adv_prob(model.encoder, ood_loader, pretrained_G, clamp=0.1)\n",
    "#     print(\"Out-of-distribution features shape: \", features_ood.shape)\n",
    "\n",
    "    fpr95, auroc, aupr, dood, dtest, yo = get_eval_results_adv(\n",
    "        np.copy(features_train),\n",
    "        np.copy(features_test),\n",
    "        np.copy(features_ood),\n",
    "        np.copy(labels_train),\n",
    "        args,\n",
    "    )\n",
    "    co = 0\n",
    "    for j in ad_index:\n",
    "        if yo[j] == 1:\n",
    "            co += 1\n",
    "\n",
    "    avg_l += [len(ad_index)]\n",
    "    avg_co += [co]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_l/100, avg_co/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st\n",
    "print(f'Mean {st.mean(avg_l)}, std: {st.stdev(avg_l)}')\n",
    "print(f'Mean {st.mean(avg_co)}, std: {st.stdev(avg_co)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
