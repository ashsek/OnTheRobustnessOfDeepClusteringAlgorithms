{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, './')\n",
    "\n",
    "from fixmatch.utils import net_builder\n",
    "from fixmatch.datasets.ssl_dataset_robust import SSL_Dataset\n",
    "from fixmatch.datasets.data_utils import get_data_loader\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(ypred, y, return_idx=False):\n",
    "    \"\"\"\n",
    "    Calculating the clustering accuracy. The predicted result must have the same number of clusters as the ground truth.\n",
    "\n",
    "    ypred: 1-D numpy vector, predicted labels\n",
    "    y: 1-D numpy vector, ground truth\n",
    "    The problem of finding the best permutation to calculate the clustering accuracy is a linear assignment problem.\n",
    "    This function construct a N-by-N cost matrix, then pass it to scipy.optimize.linear_sum_assignment to solve the assignment problem.\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(y) > 0\n",
    "    assert len(np.unique(ypred)) == len(np.unique(y))\n",
    "\n",
    "    s = np.unique(ypred)\n",
    "    t = np.unique(y)\n",
    "\n",
    "    N = len(np.unique(ypred))\n",
    "    C = np.zeros((N, N), dtype=np.int32)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            idx = np.logical_and(ypred == s[i], y == t[j])\n",
    "            C[i][j] = np.count_nonzero(idx)\n",
    "\n",
    "    # convert the C matrix to the 'true' cost\n",
    "    Cmax = np.amax(C)\n",
    "    C = Cmax - C\n",
    "    row, col = linear_sum_assignment(C)\n",
    "    # calculating the accuracy according to the optimal assignment\n",
    "    count = 0\n",
    "    for i in range(N):\n",
    "        idx = np.logical_and(ypred == s[row[i]], y == t[col[i]])\n",
    "        count += np.count_nonzero(idx)\n",
    "\n",
    "    if return_idx:\n",
    "        return 1.0 * count / len(y), row, col\n",
    "    else:\n",
    "        return 1.0 * count / len(y)\n",
    "\n",
    "\n",
    "def calculate_nmi(predict_labels, true_labels):\n",
    "    # NMI\n",
    "    nmi = metrics.normalized_mutual_info_score(true_labels, predict_labels, average_method='geometric')\n",
    "    return nmi\n",
    "\n",
    "\n",
    "def calculate_ari(predict_labels, true_labels):\n",
    "    # ARI\n",
    "    ari = metrics.adjusted_rand_score(true_labels, predict_labels)\n",
    "    return ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--load_path', type=str, default='./models/model_stl10.pth')\n",
    "parser.add_argument('--scores_path', type=str, default=None)\n",
    "parser.add_argument('--use_train_model', action='store_true')\n",
    "\n",
    "'''\n",
    "Backbone Net Configurations\n",
    "'''\n",
    "parser.add_argument('--net', type=str, default='WideResNet_stl10')\n",
    "parser.add_argument('--net_from_name', type=bool, default=False)\n",
    "parser.add_argument('--depth', type=int, default=28)\n",
    "parser.add_argument('--widen_factor', type=int, default=2)\n",
    "parser.add_argument('--leaky_slope', type=float, default=0.1)\n",
    "parser.add_argument('--dropout', type=float, default=0.0)\n",
    "\n",
    "'''\n",
    "Data Configurations\n",
    "'''\n",
    "parser.add_argument('--batch_size', type=int, default=256)\n",
    "parser.add_argument('--data_dir', type=str, default='./datasets/stl10')\n",
    "parser.add_argument('--dataset', type=str, default='stl10')\n",
    "parser.add_argument('--num_classes', type=int, default=10)\n",
    "parser.add_argument('--label_file', type=str, default=None)\n",
    "parser.add_argument('--all', type=int, default=0)\n",
    "parser.add_argument('--unlabeled', type=bool, default=False)\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(args.load_path)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "load_model = checkpoint['train_model'] if args.use_train_model else checkpoint['eval_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in list(load_model.keys()):\n",
    "\n",
    "        # Initialize the feature module with encoder_q of moco.\n",
    "        if k.startswith('model.'):\n",
    "            # remove prefix\n",
    "            load_model[k[len('model.'):]] = load_model[k]\n",
    "\n",
    "            del load_model[k]\n",
    "            # print(k)\n",
    "\n",
    "if args.net in ['WideResNet', 'WideResNet_stl10', 'WideResNet_tiny', 'resnet18', 'resnet18_cifar', 'resnet34']:\n",
    "    _net_builder = net_builder(args.net,\n",
    "                               args.net_from_name,\n",
    "                               {'depth': args.depth,\n",
    "                                'widen_factor': args.widen_factor,\n",
    "                                'leaky_slope': args.leaky_slope,\n",
    "                                'dropRate': args.dropout})\n",
    "elif args.net == 'ClusterResNet':\n",
    "    _net_builder = net_builder(args.net,\n",
    "                               args.net_from_name,\n",
    "                               {'input_size': args.input_size})\n",
    "else:\n",
    "    raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = _net_builder(num_classes=args.num_classes)\n",
    "net.load_state_dict(load_model)\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_eval_dset = SSL_Dataset(name=args.dataset, train=False, data_dir=args.data_dir, label_file=None, all=args.all, unlabeled=False)\n",
    "# print(args.all)\n",
    "\n",
    "eval_dset = _eval_dset.get_dset()\n",
    "print(len(eval_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = get_data_loader(eval_dset,\n",
    "                              args.batch_size, \n",
    "                              num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "X = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        logit = net(image)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "        \n",
    "        X.append(image.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "X = np.concatenate(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    acc = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc}, NMI: {nmi}, ARI: {ari}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gan_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "image_nc=3\n",
    "epochs = 60\n",
    "batch_size = 256\n",
    "BOX_MIN = 0\n",
    "BOX_MAX = 1\n",
    "model_num_labels = 10\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = gan_attack.GAN_Attack(device, net, model_num_labels, image_nc, BOX_MIN, BOX_MAX, '256stl10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Holding the original output object. i.e. console out\n",
    "orig_stdout = sys.stdout\n",
    "\n",
    "# Opening the file to write file deletion logs.\n",
    "f = open('outgan_train256_s10.txt', 'a+')\n",
    "\n",
    "# Changing standard out to file out. \n",
    "sys.stdout = f\n",
    "# This will write to the file. \n",
    "print(\"xyz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "advGAN.train(eval_loader, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the file.\n",
    "f.close()\n",
    "\n",
    "# replacing the original output format to stdout.\n",
    "sys.stdout = orig_stdout\n",
    "\n",
    "# This will print onto the console.\n",
    "print(\"xyz\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_stl10_epoch_600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_examples(images, labels, noise=False, bno=0, adv=False, orig=False):\n",
    "    print(type(images[0]), type(labels))\n",
    "    MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "    STD = torch.tensor([0.2023, 0.1994, 0.2010]).cuda()\n",
    "    \n",
    "    for i in range(min(len(images), 20)):\n",
    "        img = images[i]\n",
    "        img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "        npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        npimg = np.clip(npimg, 0, 1)\n",
    "        if orig:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/S10/SPICE/orig/SPICE_s10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if adv:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/S10/SPICE/adv/SPICE_s10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if noise:\n",
    "            npimg = npimg / 2 + 0.5 \n",
    "            plt.imsave(f'Images/S10/SPICE/noise/SPICE_s10_b{bno}_{i}_noise_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_adv = 0.0\n",
    "labels_pred_adv = []\n",
    "labels_gt_adv = []\n",
    "scores = []\n",
    "X_adv = []\n",
    "step = 0\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.2, 0.2)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred_adv.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt_adv.append(target.cpu().numpy())\n",
    "        X_adv.append(adv_imgs.cpu().numpy())\n",
    "        save_examples(image, labels_gt_adv[-1], bno=step, orig=True)\n",
    "        save_examples(adv_imgs, labels_pred_adv[-1], bno=step, adv=True)\n",
    "        save_examples(perturbation, labels_gt_adv[-1], bno=step, noise=True)\n",
    "        step +=1\n",
    "#         pps(image, adv_imgs, target.cpu().numpy(), torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "#         break\n",
    "#         pp(image, labels_gt)\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred_adv = np.concatenate(labels_pred_adv, axis=0)\n",
    "labels_gt_adv = np.concatenate(labels_gt_adv, axis=0)\n",
    "X_adv = np.concatenate(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "\n",
    "MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "STD = torch.tensor([0.2023, 0.1994, 0.2010]).cuda()\n",
    "\n",
    "# x = normalized_img * STD[:, None, None] + MEAN[:, None, None]\n",
    "\n",
    "\n",
    "def pp(images, labels):\n",
    "    MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "    STD = torch.tensor([0.229, 0.224, 0.225]).cuda()\n",
    "    print(type(images[0]), type(labels))\n",
    "    print(images.shape)\n",
    "#     w = \n",
    "#     h = 10\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    columns = 11\n",
    "    rows = 12\n",
    "    for i in range(35):\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        img = images[i]\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5   # unnormalize\n",
    "        img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "#         img = (img * 255).astype(np.uint8)\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5 \n",
    "#         npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        \n",
    "#         plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "        plt.imshow(img.transpose(1, 2, 0))\n",
    "#         plt.imshow(npimg)\n",
    "#         plt.title('#{}: {}'.format(i, labels[i]))\n",
    "    plt.show()\n",
    "\n",
    "count = 0\n",
    "def pps(images, adv_imgs, orig, predicted):\n",
    "    global count\n",
    "    MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "    STD = torch.tensor([0.229, 0.224, 0.225]).cuda()\n",
    "    \n",
    "    print(images.shape)\n",
    "\n",
    "    for i, _ in enumerate(images):\n",
    "        img = images[i]\n",
    "        img_a = adv_imgs[i]\n",
    "\n",
    "        img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        img_a = img_a * STD[:, None, None] + MEAN[:, None, None]\n",
    "        img_a = img_a.detach().cpu().numpy()\n",
    "        img_a = np.clip(img_a, 0, 1)\n",
    "\n",
    "        \n",
    "#         plt.show(img.transpose(1, 2, 0))\n",
    "        plt.imsave(f'outputs/stl10/orig/{count}_{orig[i]}.png', img.transpose(1, 2, 0))\n",
    "        plt.imsave(f'outputs/stl10/adv/{count}_{predicted[i]}.png', img_a.transpose(1, 2, 0))\n",
    "        count += 1\n",
    "        \n",
    "#         return \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_adv = 0.0\n",
    "labels_pred_adv = []\n",
    "labels_gt_adv = []\n",
    "scores = []\n",
    "X_adv = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.2, 0.2)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred_adv.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt_adv.append(target.cpu().numpy())\n",
    "        X_adv.append(adv_imgs.cpu().numpy())\n",
    "#         pps(image, adv_imgs, target.cpu().numpy(), torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "#         break\n",
    "#         pp(image, labels_gt)\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred_adv = np.concatenate(labels_pred_adv, axis=0)\n",
    "labels_gt_adv = np.concatenate(labels_gt_adv, axis=0)\n",
    "X_adv = np.concatenate(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred_adv, labels_gt_adv)\n",
    "except:\n",
    "    acc = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmi = calculate_nmi(labels_pred_adv, labels_gt_adv)\n",
    "ari = calculate_ari(labels_pred_adv, labels_gt_adv)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, target, _ in eval_loader:\n",
    "#     targets, inputs = target.to(device), image.to(device)\n",
    "#     perturbation = pretrained_G(inputs)\n",
    "#     perturbation = torch.clamp(perturbation, -0.2, 0.2)\n",
    "#     adv_imgs = perturbation + inputs\n",
    "# #     print(inputs[0])\n",
    "#     pp(inputs, targets)\n",
    "#     pp(adv_imgs, targets)\n",
    "#     pp(perturbation, targets)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Experirments for TSNE/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.copy()\n",
    "X2_adv = X_adv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "X2 = X2.reshape(8000, 3*96*96)\n",
    "X2 = X2.T\n",
    "\n",
    "pca_adv = PCA(n_components=3)\n",
    "\n",
    "X2_adv = X2.reshape(8000, 3*96*96)\n",
    "X2_adv = X2_adv.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X2)\n",
    "pca_x = pca.components_\n",
    "\n",
    "pca_adv.fit(X2_adv)\n",
    "pca_adv_x = pca_adv.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_adv_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "class2colors = sns.color_palette(\"tab10\", 10) # 10 colors\n",
    "\n",
    "class2markers = [\"+\", \"x\", \"*\", \"P\", \"o\", \"^\", \"d\", \"p\", \"s\", \"8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check3dboundary(x,y,z):\n",
    "    return -0.04 <= min(x,y,z) and max(x,y,z) <= 0.04\n",
    "\n",
    "def check2dboundary(x,y):\n",
    "    return -0.04 <= min(x,y) and max(x,y) <= 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerBase\n",
    "\n",
    "list_color  = class2colors[:]\n",
    "list_mak    =  [\"o\"]*10\n",
    "lis = [\"plane\", \"bird\", \"car\", \"cat\", \"deer\", \"dog\", \"horse\", \"monkey\", \"ship\", \"truck\"]\n",
    "\n",
    "list_lab    = [j[0].upper() + j[1:] for j in lis]\n",
    "\n",
    "\n",
    "list_color2 = ['tab:red', 'tab:blue']\n",
    "list_mak2 = ['o', 'o']\n",
    "list_lab2  = ['Adversarial', 'Original']\n",
    "\n",
    "# ax = plt.gca()\n",
    "\n",
    "class MarkerHandler(HandlerBase):\n",
    "    def create_artists(self, legend, tup,xdescent, ydescent,\n",
    "                        width, height, fontsize,trans):\n",
    "        return [plt.Line2D([width/2], [height/2.],ls=\"\",\n",
    "                       marker=tup[1],color=tup[0], transform=trans)]\n",
    "\n",
    "\n",
    "# ax.legend(list(zip(list_color,list_mak)), list_lab, handler_map={tuple:MarkerHandler()}) \n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "# ax.scatter3D(pca_adv_x[0], pca_adv_x[1], pca_adv_x[2], color='red', marker='^')\n",
    "\n",
    "# gt -> marker; predicted -> color\n",
    "for i in range(80):\n",
    "#     for clas in range(10):\n",
    "#         if labels_pred[i] == clas:\n",
    "#     ax.scatter3D(pca_x[0, i], pca_x[1, i], pca_x[2, i], color=class2colors[labels_pred[i]], marker=class2markers[labels_gt[i]], label=labels_gt, edgecolor='black')\n",
    "    ax.scatter3D(pca_x[0, i], pca_x[1, i], pca_x[2, i], color=class2colors[labels_pred[i]], edgecolor='black')\n",
    "ax.set_zlim(-0.04, 0.04)\n",
    "ax.set_xlim(-0.04, 0.04)\n",
    "ax.set_ylim(-0.04, 0.04)\n",
    "# ax.xticks(color='w')\n",
    "# ax.yticks(color='w')\n",
    "# ax.zticks(color='w')\n",
    "# ax.set_xticks([])\n",
    "# ax.set(ylabel=None)\n",
    "# ax.set(xlabel=None)\n",
    "# ax.tick_params(axis='x', colors='white')\n",
    "# ax.tick_params(axis='y', colors='white')\n",
    "# ax.tick_params(axis='z', colors='white')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "# plt.legend(class2colors, [0]*10)\n",
    "ax.legend(list(zip(list_color,list_mak)), list_lab, handler_map={tuple:MarkerHandler()}, fontsize = 8) \n",
    "plt.savefig('3d_orig.png')\n",
    "\n",
    "    # plt.ylim((-0.04, 0.04))\n",
    "# plt.xlim((-0.04, 0.04))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "# ax.scatter3D(pca_adv_x[0], pca_adv_x[1], pca_adv_x[2], color='red', marker='^')\n",
    "\n",
    "plt.ylim((-0.04, 0.04))\n",
    "plt.xlim((-0.04, 0.04))\n",
    "# gt -> marker; predicted -> color\n",
    "for i in range(8000):\n",
    "#     for clas in range(10):\n",
    "#         if labels_pred_adv[i] == clas:\n",
    "    if check3dboundary(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i]):\n",
    "        ax.scatter3D(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i], color=class2colors[labels_pred_adv[i]], marker=class2markers[labels_gt_adv[i]], edgecolor='black')\n",
    "\n",
    "ax.set_zlim(-0.04, 0.04)\n",
    "ax.set_xlim(-0.04, 0.04)\n",
    "ax.set_ylim(-0.04, 0.04)\n",
    "\n",
    "# plt.ylim((-0.04, 0.04))\n",
    "# plt.xlim((-0.04, 0.04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "# ax.scatter3D(pca_adv_x[0], pca_adv_x[1], pca_adv_x[2], color='red', marker='^')\n",
    "\n",
    "# plt.ylim((-0.04, 0.04))\n",
    "# plt.xlim((-0.04, 0.04))\n",
    "# # plt.zlim((-0.04, 0.04))\n",
    "\n",
    "# gt -> color; predicted -> marker\n",
    "# ax.set_zlim(-0.04, 0.04)\n",
    "# ax.set_xlim(-0.04, 0.04)\n",
    "# ax.set_ylim(-0.04, 0.04)\n",
    "\n",
    "for i in range(8000):\n",
    "#     for clas in range(10):\n",
    "#         if labels_pred_adv[i] == clas:\n",
    "    ax.scatter3D(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i], color=class2colors[labels_gt_adv[i]], marker=class2markers[labels_pred_adv[i]], edgecolor='black')\n",
    "\n",
    "ax.set_zlim(-0.04, 0.04)\n",
    "ax.set_xlim(-0.04, 0.04)\n",
    "ax.set_ylim(-0.04, 0.04)\n",
    "\n",
    "# plt.ylim((-0.04, 0.04))\n",
    "# plt.xlim((-0.04, 0.04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.scatter3D(pca_adv_x[0], pca_adv_x[1], pca_adv_x[2], color='red', marker='^')\n",
    "\n",
    "# gt -> color; predicted -> marker\n",
    "for i in range(8000):\n",
    "#     for clas in range(10):\n",
    "#         if labels_pred[i] == clas:\n",
    "    ax.scatter3D(pca_x[0, i], pca_x[1, i], pca_x[2, i], color=class2colors[labels_gt[i]], edgecolor='black')\n",
    "\n",
    "ax.set_zlim(-0.04, 0.04)\n",
    "ax.set_xlim(-0.04, 0.04)\n",
    "ax.set_ylim(-0.04, 0.04)\n",
    "\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "# plt.legend(class2colors, [0]*10)\n",
    "ax.legend(list(zip(list_color,list_mak)), list_lab, handler_map={tuple:MarkerHandler()}, loc='upper right', bbox_to_anchor=(1.2, 1.05)) \n",
    "plt.savefig('3d_orig.png', dpi=600, bbox_inches='tight')\n",
    "    # plt.ylim((-0.04, 0.04))\n",
    "# plt.xlim((-0.04, 0.04))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "# ax.scatter3D(pca_adv_x[0], pca_adv_x[1], pca_adv_x[2], color='red', marker='^')\n",
    "\n",
    "# bbox uinches = tight, dpi 600, \n",
    "\n",
    "# plt.ylim((-0.04, 0.04))\n",
    "# plt.xlim((-0.04, 0.04))\n",
    "# # plt.zlim((-0.04, 0.04))\n",
    "\n",
    "# gt -> color; predicted -> marker\n",
    "# ax.set_zlim(-0.04, 0.04)\n",
    "# ax.set_xlim(-0.04, 0.04)  \n",
    "# ax.set_ylim(-0.04, 0.04)\n",
    "\n",
    "for i in range(8000):\n",
    "#     for clas in range(10):\n",
    "#         if labels_pred_adv[i] == clas:\n",
    "#     if -0.04 <= min(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i]) and max(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i]) <= 0.04: \n",
    "    if check3dboundary(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i]):\n",
    "        ax.scatter3D(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i], color=class2colors[labels_gt_adv[i]], edgecolor='black')\n",
    "\n",
    "ax.set_zlim(-0.04, 0.04)\n",
    "ax.set_xlim(-0.04, 0.04)\n",
    "ax.set_ylim(-0.04, 0.04)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "\n",
    "# ax.legend(list(zip(list_color,list_mak)), list_lab, handler_map={tuple:MarkerHandler()}, loc='upper right', bbox_to_anchor=(1.2, 1.05)) \n",
    "# ax.legend(list(zip(list_color,list_mak)), list_lab, handler_map={tuple:MarkerHandler()}, fontsize=9, handletextpad=0)\n",
    "plt.savefig('3d_adv.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "# plt.legend(class2colors, [0]*10)\n",
    "# plt.ylim((-0.04, 0.04))\n",
    "# plt.xlim((-0.04, 0.04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "# ax.scatter3D(pca_adv_x[0], pca_adv_x[1], pca_adv_x[2], color='red', marker='^')\n",
    "\n",
    "# plt.ylim((-0.04, 0.04))\n",
    "# plt.xlim((-0.04, 0.04))\n",
    "# # plt.zlim((-0.04, 0.04))\n",
    "\n",
    "# gt -> color; predicted -> marker\n",
    "# ax.set_zlim(-0.04, 0.04)\n",
    "# ax.set_xlim(-0.04, 0.04)\n",
    "# ax.set_ylim(-0.04, 0.04)\n",
    "\n",
    "for i in range(8000):\n",
    "#     for clas in range(10):\n",
    "#         if labels_pred_adv[i] == clas:\n",
    "#     if -0.04 <= min(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i]) and max(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i]) <= 0.04: \n",
    "    if check3dboundary(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i]):\n",
    "        ax.scatter3D(pca_x[0, i], pca_x[1, i], pca_x[2, i], color=\"tab:blue\", marker='o')\n",
    "        ax.scatter3D(pca_adv_x[0, i], pca_adv_x[1, i], pca_adv_x[2, i], color=\"tab:red\", marker='o')\n",
    "\n",
    "ax.set_zlim(-0.04, 0.04)\n",
    "ax.set_xlim(-0.04, 0.04)\n",
    "ax.set_ylim(-0.04, 0.04)\n",
    "ax.set_xticklabels(['1'], color='w')\n",
    "ax.set_yticklabels(['1'], color='w')\n",
    "ax.set_zticklabels(['1'], color='w')\n",
    "ax.tick_params(False)\n",
    "# plt.legend(class2colors, [0]*10)\n",
    "ax.legend(list(zip(list_color2,list_mak2)), list_lab2, handler_map={tuple:MarkerHandler()}, loc='upper center', fontsize=15, ncol=2) \n",
    "plt.tight_layout()\n",
    "plt.savefig('3d_both.pdf', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.copy()\n",
    "X2_adv = X_adv.copy()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X2 = X2.reshape(8000, 3*96*96)\n",
    "X2 = X2.T\n",
    "\n",
    "pca_adv = PCA(n_components=2)\n",
    "\n",
    "X2_adv = X2.reshape(8000, 3*96*96)\n",
    "X2_adv = X2_adv.T\n",
    "\n",
    "pca.fit(X2)\n",
    "pca_x = pca.components_\n",
    "\n",
    "pca_adv.fit(X2_adv)\n",
    "pca_adv_x = pca_adv.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(pca_x[0], pca_x[1], color=\"red\", marker='^', edgecolor='black')\n",
    "# plt.scatter(pca_adv_x[0], pca_adv_x[1], color=\"blue\", marker='o', edgecolor='black')\n",
    "# plt.show()\n",
    "\n",
    "#markers are predicted labels, and orig is blue and adv is red.\n",
    "for i in range(8000):\n",
    "    plt.scatter(pca_x[0, i], pca_x[1, i], color=\"tab:blue\", marker='o', edgecolor='black')\n",
    "    plt.scatter(pca_adv_x[0, i], pca_adv_x[1, i], color=\"tab:red\",marker='o', edgecolor='black')\n",
    "\n",
    "plt.ylim((-0.04, 0.04))\n",
    "plt.xlim((-0.04, 0.04))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(pca_x[0], pca_x[1])\n",
    "# ax = plt.axes(projection='3d')\n",
    "# ax.scatter3D(pca_x[0], pca_x[1], pca_x[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %matplotlib notebook\n",
    "# # plt.plot(pca_x[0], pca_x[1])\n",
    "# ax = plt.axes(projection='3d')\n",
    "# ax.scatter3D(pca_adv_x[0], pca_adv_x[1], pca_adv_x[2], color='red', marker='^')\n",
    "# ax.scatter3D(pca_x[0], pca_x[1], pca_x[2], color='blue', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(pca_x[0], pca_x[1], color=\"red\", marker='^', edgecolor='black')\n",
    "# plt.scatter(pca_adv_x[0], pca_adv_x[1], color=\"blue\", marker='o', edgecolor='black')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8000):\n",
    "    for clas in range(10):\n",
    "        if labels_pred_adv[i] == clas:\n",
    "            plt.scatter(pca_adv_x[0, i], pca_adv_x[1, i], color=color_l[clas], marker='o', edgecolor='black')\n",
    "plt.ylim((-0.04, 0.04))\n",
    "plt.xlim((-0.04, 0.04))\n",
    "plt.show()\n",
    "#     else:\n",
    "#         plt.scatter(pca_adv_x[0, i], pca_adv_x[1, i], color=\"blue\", marker='^', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8000):\n",
    "    for clas in range(10):\n",
    "        if labels_pred[i] == clas:\n",
    "            plt.scatter(pca_x[0, i], pca_x[1, i], color=color_l[clas], marker='o', edgecolor='black')\n",
    "plt.ylim((-0.04, 0.04))\n",
    "plt.xlim((-0.04, 0.04))\n",
    "plt.show()\n",
    "#     else:\n",
    "#         plt.scatter(pca_adv_x[0, i], pca_adv_x[1, i], color=\"blue\", marker='^', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferability attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_generator_path = '../Generator_Models/STL10/netG_CC_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.3, 0.3)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")\n",
    "\n",
    "for image, target, _ in eval_loader:\n",
    "    targets, inputs = target.to(device), image.to(device)\n",
    "    perturbation = pretrained_G(inputs)\n",
    "    perturbation = torch.clamp(perturbation, -0.3, 0.3)\n",
    "    adv_imgs = perturbation + inputs\n",
    "#     print(inputs[0])\n",
    "    pp(inputs, targets)\n",
    "    pp(adv_imgs, targets)\n",
    "    pp(perturbation, targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_generator_path = '../Generator_Models/STL10/netG_MICE_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.5, 0.5)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "# print(perturbation)\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "    \n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")\n",
    "\n",
    "for image, target, _ in eval_loader:\n",
    "    targets, inputs = target.to(device), image.to(device)\n",
    "    perturbation = pretrained_G(inputs)\n",
    "#     perturbation = torch.clamp(perturbation, -0.5, 0.5)\n",
    "    adv_imgs = perturbation + inputs\n",
    "#     print(inputs[0])\n",
    "    pp(inputs, targets)\n",
    "    pp(adv_imgs, targets)\n",
    "    pp(perturbation, targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pretrained_generator_path = '../Generator_Models/STL10/netG_SCAN_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.2, 0.2)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")\n",
    "\n",
    "for image, target, _ in eval_loader:\n",
    "    targets, inputs = target.to(device), image.to(device)\n",
    "    perturbation = pretrained_G(inputs)\n",
    "    perturbation = torch.clamp(perturbation, -0.2, 0.2)\n",
    "    adv_imgs = perturbation + inputs\n",
    "#     print(inputs[0])\n",
    "    pp(inputs, targets)\n",
    "    pp(adv_imgs, targets)\n",
    "    pp(perturbation, targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_generator_path = '../Generator_Models/STL10/netG_RUC_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.2, 0.2)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")\n",
    "\n",
    "for image, target, _ in eval_loader:\n",
    "    targets, inputs = target.to(device), image.to(device)\n",
    "    perturbation = pretrained_G(inputs)\n",
    "    perturbation = torch.clamp(perturbation, -0.2, 0.2)\n",
    "    adv_imgs = perturbation + inputs\n",
    "#     print(inputs[0])\n",
    "    pp(inputs, targets)\n",
    "    pp(adv_imgs, targets)\n",
    "    pp(perturbation, targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_generator_path = '../Generator_Models/STL10/netG_NNM_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.2, 0.2)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "# print(perturbation)\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "    \n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")\n",
    "\n",
    "for image, target, _ in eval_loader:\n",
    "    targets, inputs = target.to(device), image.to(device)\n",
    "    perturbation = pretrained_G(inputs)\n",
    "    perturbation = torch.clamp(perturbation, -0.2, 0.2)\n",
    "    adv_imgs = perturbation + inputs\n",
    "#     print(inputs[0])\n",
    "    pp(inputs, targets)\n",
    "    pp(adv_imgs, targets)\n",
    "    pp(perturbation, targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Experimetns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_stl10_epoch_600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "clamp = [0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    acc_adv = 0.0\n",
    "    labels_pred = []\n",
    "    labels_gt = []\n",
    "    scores = []\n",
    "    norm = 0.0\n",
    "    with torch.no_grad():\n",
    "        for image, target, _ in eval_loader:\n",
    "            image = image.type(torch.FloatTensor).cuda()\n",
    "            perturbation = pretrained_G(image)\n",
    "            perturbation = torch.clamp(perturbation, -j, j)    \n",
    "            norm += torch.mean(torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1)).to('cpu').item()\n",
    "            adv_imgs = perturbation + image\n",
    "\n",
    "            logit = net(adv_imgs)\n",
    "\n",
    "            scores.append(logit.cpu().numpy())\n",
    "\n",
    "            labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "            labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "    scores = np.concatenate(scores, axis=0)\n",
    "    labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "    labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "    try:\n",
    "        acc2 = calculate_acc(labels_pred, labels_gt)\n",
    "    except:\n",
    "        acc = -1\n",
    "\n",
    "    nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "    ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "    print(f'clamp {j} avg norm: {norm/len(eval_loader)}')\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc2))\n",
    "    norm_l.append(norm/len(eval_loader))\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, label = \"line 1\", linestyle=\"-\")\n",
    "# plt.plot(y, x, label = \"line 2\", linestyle=\"--\")\n",
    "# plt.plot(x, np.sin(x), label = \"curve 1\", linestyle=\"-.\")\n",
    "# plt.plot(x, np.cos(x), label = \"curve 2\", linestyle=\":\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(norm_l, nmi_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(norm_l, ari_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(norm_l, acc_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Perturbation Norm\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('spice_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same acc formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_cus\n",
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "clamp = [0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    acc_adv = 0.0\n",
    "    labels_pred = []\n",
    "    labels_gt = []\n",
    "    scores = []\n",
    "    norm = 0.0\n",
    "    with torch.no_grad():\n",
    "        for image, target, _ in eval_loader:\n",
    "            image = image.type(torch.FloatTensor).cuda()\n",
    "            perturbation = pretrained_G(image)\n",
    "            perturbation = torch.clamp(perturbation, -j, j)    \n",
    "            norm += torch.mean(torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1)).to('cpu').item()\n",
    "            adv_imgs = perturbation + image\n",
    "#             adv_imgs = torch.clamp(adv_imgs, -1, 1)\n",
    "            \n",
    "            logit = net(adv_imgs)\n",
    "\n",
    "            scores.append(logit.cpu().numpy())\n",
    "            \n",
    "            \n",
    "\n",
    "            labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "            labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "    scores = np.concatenate(scores, axis=0)\n",
    "    labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "    labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "    class_names = ['airplane',\n",
    "                 'bird',\n",
    "                 'car',\n",
    "                 'cat',\n",
    "                 'deer',\n",
    "                 'dog',\n",
    "                 'horse',\n",
    "                 'monkey',\n",
    "                 'ship',\n",
    "                 'truck']\n",
    "    labels_gt = torch.from_numpy(labels_gt).cuda()\n",
    "    labels_pred = torch.from_numpy(labels_pred).cuda()\n",
    "    clustering_stats_adv = eval_cus.check(labels_gt, labels_pred, 20, class_names, \n",
    "                                        compute_confusion_matrix=True, \n",
    "                    confusion_matrix_file=None, cf20=False)\n",
    "    acc2 = clustering_stats_adv['ACC']\n",
    "    nmi = clustering_stats_adv['NMI']\n",
    "    ari = clustering_stats_adv['ARI']\n",
    "    \n",
    "#     try:\n",
    "#         acc2 = calculate_acc(labels_pred, labels_gt)\n",
    "#     except:\n",
    "#         acc = -1\n",
    "\n",
    "#     nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "#     ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "    print(f'clamp {j} avg norm: {norm/len(eval_loader)}')\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc2))\n",
    "    norm_l.append(norm/len(eval_loader))\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_cus\n",
    "\n",
    "importlib.reload(eval_cus)\n",
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "# clamp = [0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "clamp = [0, 0.2, 1]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    acc_adv = 0.0\n",
    "    labels_pred = []\n",
    "    labels_gt = []\n",
    "    scores = []\n",
    "    norm = 0.0\n",
    "    with torch.no_grad():\n",
    "        for image, target, _ in eval_loader:\n",
    "            image = image.type(torch.FloatTensor).cuda()\n",
    "            perturbation = pretrained_G(image)\n",
    "            perturbation = torch.clamp(perturbation, -j, j)    \n",
    "            norm += torch.mean(torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1)).to('cpu').item()\n",
    "            adv_imgs = perturbation + image\n",
    "#             adv_imgs = torch.clamp(adv_imgs, -1, 1)\n",
    "            \n",
    "            logit = net(adv_imgs)\n",
    "\n",
    "            scores.append(logit.cpu().numpy())\n",
    "            \n",
    "            \n",
    "\n",
    "            labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "            labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "    scores = np.concatenate(scores, axis=0)\n",
    "    labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "    labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "    class_names = ['airplane',\n",
    "                 'bird',\n",
    "                 'car',\n",
    "                 'cat',\n",
    "                 'deer',\n",
    "                 'dog',\n",
    "                 'horse',\n",
    "                 'monkey',\n",
    "                 'ship',\n",
    "                 'truck']\n",
    "    labels_gt = torch.from_numpy(labels_gt).cuda()\n",
    "    labels_pred = torch.from_numpy(labels_pred).cuda()\n",
    "    clustering_stats_adv = eval_cus.check(labels_gt, labels_pred, 20, class_names, \n",
    "                                        compute_confusion_matrix=True, \n",
    "                    confusion_matrix_file=None, cf20=False, output_file2=f'SPICE_s10_{j}_n{norm}.pdf')\n",
    "    acc2 = clustering_stats_adv['ACC']\n",
    "    nmi = clustering_stats_adv['NMI']\n",
    "    ari = clustering_stats_adv['ARI']\n",
    "    \n",
    "#     try:\n",
    "#         acc2 = calculate_acc(labels_pred, labels_gt)\n",
    "#     except:\n",
    "#         acc = -1\n",
    "\n",
    "#     nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "#     ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "    print(f'clamp {j} avg norm: {norm/len(eval_loader)}')\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc2))\n",
    "    norm_l.append(norm/len(eval_loader))\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
