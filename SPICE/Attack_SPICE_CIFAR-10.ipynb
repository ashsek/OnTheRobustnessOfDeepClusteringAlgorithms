{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, './')\n",
    "\n",
    "from fixmatch.utils import net_builder\n",
    "from fixmatch.datasets.ssl_dataset_robust import SSL_Dataset\n",
    "from fixmatch.datasets.data_utils import get_data_loader\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(ypred, y, return_idx=False):\n",
    "    \"\"\"\n",
    "    Calculating the clustering accuracy. The predicted result must have the same number of clusters as the ground truth.\n",
    "\n",
    "    ypred: 1-D numpy vector, predicted labels\n",
    "    y: 1-D numpy vector, ground truth\n",
    "    The problem of finding the best permutation to calculate the clustering accuracy is a linear assignment problem.\n",
    "    This function construct a N-by-N cost matrix, then pass it to scipy.optimize.linear_sum_assignment to solve the assignment problem.\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(y) > 0\n",
    "    assert len(np.unique(ypred)) == len(np.unique(y))\n",
    "\n",
    "    s = np.unique(ypred)\n",
    "    t = np.unique(y)\n",
    "\n",
    "    N = len(np.unique(ypred))\n",
    "    C = np.zeros((N, N), dtype=np.int32)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            idx = np.logical_and(ypred == s[i], y == t[j])\n",
    "            C[i][j] = np.count_nonzero(idx)\n",
    "\n",
    "    # convert the C matrix to the 'true' cost\n",
    "    Cmax = np.amax(C)\n",
    "    C = Cmax - C\n",
    "    row, col = linear_sum_assignment(C)\n",
    "    # calculating the accuracy according to the optimal assignment\n",
    "    count = 0\n",
    "    for i in range(N):\n",
    "        idx = np.logical_and(ypred == s[row[i]], y == t[col[i]])\n",
    "        count += np.count_nonzero(idx)\n",
    "\n",
    "    if return_idx:\n",
    "        return 1.0 * count / len(y), row, col\n",
    "    else:\n",
    "        return 1.0 * count / len(y)\n",
    "\n",
    "\n",
    "def calculate_nmi(predict_labels, true_labels):\n",
    "    # NMI\n",
    "    nmi = metrics.normalized_mutual_info_score(true_labels, predict_labels, average_method='geometric')\n",
    "    return nmi\n",
    "\n",
    "\n",
    "def calculate_ari(predict_labels, true_labels):\n",
    "    # ARI\n",
    "    ari = metrics.adjusted_rand_score(true_labels, predict_labels)\n",
    "    return ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--load_path', type=str, default='./models/model_cifar10_cls_res18.pth')\n",
    "parser.add_argument('--scores_path', type=str, default=None)\n",
    "parser.add_argument('--use_train_model', action='store_true')\n",
    "\n",
    "'''\n",
    "Backbone Net Configurations\n",
    "'''\n",
    "parser.add_argument('--net', type=str, default='resnet18_cifar')\n",
    "parser.add_argument('--net_from_name', type=bool, default=False)\n",
    "parser.add_argument('--depth', type=int, default=28)\n",
    "parser.add_argument('--widen_factor', type=int, default=2)\n",
    "parser.add_argument('--leaky_slope', type=float, default=0.1)\n",
    "parser.add_argument('--dropout', type=float, default=0.0)\n",
    "\n",
    "'''\n",
    "Data Configurations\n",
    "'''\n",
    "parser.add_argument('--batch_size', type=int, default=256)\n",
    "parser.add_argument('--data_dir', type=str, default='./datasets/cifar10')\n",
    "parser.add_argument('--dataset', type=str, default='cifar10')\n",
    "parser.add_argument('--num_classes', type=int, default=10)\n",
    "parser.add_argument('--label_file', type=str, default=None)\n",
    "parser.add_argument('--all', type=int, default=0)\n",
    "parser.add_argument('--unlabeled', type=bool, default=False)\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(args.load_path)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "load_model = checkpoint['train_model'] if args.use_train_model else checkpoint['eval_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in list(load_model.keys()):\n",
    "\n",
    "        # Initialize the feature module with encoder_q of moco.\n",
    "        if k.startswith('model.'):\n",
    "            # remove prefix\n",
    "            load_model[k[len('model.'):]] = load_model[k]\n",
    "\n",
    "            del load_model[k]\n",
    "            # print(k)\n",
    "\n",
    "if args.net in ['WideResNet', 'WideResNet_stl10', 'WideResNet_tiny', 'resnet18', 'resnet18_cifar', 'resnet34']:\n",
    "    _net_builder = net_builder(args.net,\n",
    "                               args.net_from_name,\n",
    "                               {'depth': args.depth,\n",
    "                                'widen_factor': args.widen_factor,\n",
    "                                'leaky_slope': args.leaky_slope,\n",
    "                                'dropRate': args.dropout})\n",
    "elif args.net == 'ClusterResNet':\n",
    "    _net_builder = net_builder(args.net,\n",
    "                               args.net_from_name,\n",
    "                               {'input_size': args.input_size})\n",
    "else:\n",
    "    raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = _net_builder(num_classes=args.num_classes)\n",
    "net.load_state_dict(load_model)\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_eval_dset = SSL_Dataset(name=args.dataset, train=False, data_dir=args.data_dir, label_file=None, all=args.all, unlabeled=False)\n",
    "# print(args.all)\n",
    "\n",
    "eval_dset = _eval_dset.get_dset()\n",
    "print(len(eval_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = get_data_loader(eval_dset,\n",
    "                              args.batch_size, \n",
    "                              num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "#         image = torch.clamp(image, -1, 1)\n",
    "        logit = net(image)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    acc = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc}, NMI: {nmi}, ARI: {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_cus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions, features = get_predictions_adv(config, dataloader, model, return_features=True)\n",
    "# out = predictions[0]['predictions']\n",
    "# targets = predictions[0]['targets']\n",
    "class_names = ('airplane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "labels_gt = torch.from_numpy(labels_gt).cuda()\n",
    "labels_pred = torch.from_numpy(labels_pred).cuda()\n",
    "\n",
    "clustering_stats_adv = eval_cus.check(labels_gt, labels_pred, 10, class_names, \n",
    "                                        compute_confusion_matrix=True, \n",
    "                    confusion_matrix_file=None)\n",
    "print(clustering_stats_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gan_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "image_nc=3\n",
    "epochs = 60\n",
    "batch_size = 256\n",
    "BOX_MIN = 0\n",
    "BOX_MAX = 1\n",
    "model_num_labels = 10\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = gan_attack.GAN_Attack(device, net, model_num_labels, image_nc, BOX_MIN, BOX_MAX, '256cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Holding the original output object. i.e. console out\n",
    "orig_stdout = sys.stdout\n",
    "\n",
    "# Opening the file to write file deletion logs.\n",
    "f = open('outgan_train_256c10.txt', 'a+')\n",
    "\n",
    "# Changing standard out to file out. \n",
    "sys.stdout = f\n",
    "# This will write to the file. \n",
    "print(\"xyz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "GAN.train(eval_loader, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the file.\n",
    "f.close()\n",
    "\n",
    "# replacing the original output format to stdout.\n",
    "sys.stdout = orig_stdout\n",
    "\n",
    "# This will print onto the console.\n",
    "print(\"xyz\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_2cifar10_epoch_600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.22, 0.22)        \n",
    "        adv_imgs = perturbation + image\n",
    "#         adv_imgs = torch.clamp(adv_imgs, -1, 1)\n",
    "#         print(image[0])\n",
    "#         print(adv_imgs[0])\n",
    "\n",
    "\n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ('airplane', 'car', 'bird', 'cat',\n",
    "       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "labels_gt = torch.from_numpy(labels_gt).cuda()\n",
    "labels_pred = torch.from_numpy(labels_pred).cuda()\n",
    "clustering_stats_adv = eval_cus.check(labels_gt, labels_pred, 10, class_names, \n",
    "                                    compute_confusion_matrix=True, \n",
    "                confusion_matrix_file=None)\n",
    "\n",
    "print(clustering_stats_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "\n",
    "MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "STD = torch.tensor([0.2023, 0.1994, 0.2010]).cuda()\n",
    "\n",
    "# x = normalized_img * STD[:, None, None] + MEAN[:, None, None]\n",
    "\n",
    "def pp(images, labels):\n",
    "    MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "    STD = torch.tensor([0.229, 0.224, 0.225]).cuda()\n",
    "    print(type(images[0]), type(labels))\n",
    "    print(images.shape)\n",
    "#     w = \n",
    "#     h = 10\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    columns = 11\n",
    "    rows = 12\n",
    "    for i in range(35):\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        img = images[i]\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5   # unnormalize\n",
    "        img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "#         img = (img * 255).astype(np.uint8)\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5 \n",
    "#         npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        \n",
    "#         plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "        plt.imshow(img.transpose(1, 2, 0))\n",
    "#         plt.imshow(npimg)\n",
    "#         plt.title('#{}: {}'.format(i, labels[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_examples(images, labels, noise=False, bno=0, adv=False, orig=False):\n",
    "    print(type(images[0]), type(labels))\n",
    "    MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "    STD = torch.tensor([0.229, 0.224, 0.225]).cuda()\n",
    "    \n",
    "    for i in range(min(len(images), 20)):\n",
    "        img = images[i]\n",
    "        img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "        npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        npimg = np.clip(npimg, 0, 1)\n",
    "        if orig:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/C10/SPICE/orig/SPICE_c10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if adv:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/C10/SPICE/adv/SPICE_c10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if noise:\n",
    "            npimg = npimg / 2 + 0.5 \n",
    "            plt.imsave(f'Images/C10/SPICE/noise/SPICE_c10_b{bno}_{i}_noise_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "step = 0\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.22, 0.22)        \n",
    "        adv_imgs = perturbation + image\n",
    "\n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "        \n",
    "        save_examples(image, labels_gt[-1], bno=step, orig=True)\n",
    "        save_examples(adv_imgs, labels_pred[-1], bno=step, adv=True)\n",
    "        save_examples(perturbation, labels_gt[-1], bno=step, noise=True)\n",
    "        step += 1\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, target, _ in eval_loader:\n",
    "    targets, inputs = target.to(device), image.to(device)\n",
    "    perturbation = pretrained_G(inputs)\n",
    "    perturbation = torch.clamp(perturbation, -0.22, 0.22)\n",
    "    adv_imgs = perturbation + inputs\n",
    "#     adv_imgs = torch.clamp(adv_imgs, 0, 1)\n",
    "#     print(inputs[0])\n",
    "#     print(adv_imgs[0])\n",
    "    pp(inputs, targets)\n",
    "    pp(adv_imgs, targets)\n",
    "#     pp(perturbation, targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -1, 1)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "# except:\n",
    "#     acc = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Base MiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_MICE_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.3, 0.3)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_MICE_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.3, 0.3)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_NNM_cifar-10_epoch_570.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.17, 0.17)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_SCAN_cifar-10_epoch_1200.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.17, 0.17)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base RUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_RUC_cifar-10_epoch600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc_adv = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, target, _ in eval_loader:\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        perturbation = pretrained_G(image)\n",
    "        perturbation = torch.clamp(perturbation, -0.17, 0.17)        \n",
    "        adv_imgs = perturbation + image\n",
    "        \n",
    "        logit = net(adv_imgs)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "\n",
    "try:\n",
    "    acc_adv = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "    \n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_adv}, NMI: {nmi}, ARI: {ari}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_2cifar10_epoch_600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "# clamp = [0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "clamp = [0, 0.22, 1]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    acc_adv = 0.0\n",
    "    labels_pred = []\n",
    "    labels_gt = []\n",
    "    scores = []\n",
    "    norm = 0.0\n",
    "    with torch.no_grad():\n",
    "        for image, target, _ in eval_loader:\n",
    "            image = image.type(torch.FloatTensor).cuda()\n",
    "            perturbation = pretrained_G(image)\n",
    "            perturbation = torch.clamp(perturbation, -j, j)    \n",
    "            norm += torch.mean(torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1)).to('cpu').item()\n",
    "            adv_imgs = perturbation + image\n",
    "#             adv_imgs = torch.clamp(adv_imgs, -1, 1)\n",
    "            \n",
    "            logit = net(adv_imgs)\n",
    "\n",
    "            scores.append(logit.cpu().numpy())\n",
    "            \n",
    "            \n",
    "\n",
    "            labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "            labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "    scores = np.concatenate(scores, axis=0)\n",
    "    labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "    labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "    class_names = ('airplane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    labels_gt = torch.from_numpy(labels_gt).cuda()\n",
    "    labels_pred = torch.from_numpy(labels_pred).cuda()\n",
    "    clustering_stats_adv = eval_cus.check(labels_gt, labels_pred, 10, class_names, \n",
    "                                        compute_confusion_matrix=True, \n",
    "                    confusion_matrix_file=None, output_file2=f'SPICE_C10_{j}_n{norm/len(eval_loader)}.pdf')\n",
    "    acc2 = clustering_stats_adv['ACC']\n",
    "    nmi = clustering_stats_adv['NMI']\n",
    "    ari = clustering_stats_adv['ARI']\n",
    "    \n",
    "#     try:\n",
    "#         acc2 = calculate_acc(labels_pred, labels_gt)\n",
    "#     except:\n",
    "#         acc = -1\n",
    "\n",
    "#     nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "#     ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "    print(f'clamp {j} avg norm: {norm/len(eval_loader)}')\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc2))\n",
    "    norm_l.append(norm/len(eval_loader))\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, label = \"line 1\", linestyle=\"-\")\n",
    "# plt.plot(y, x, label = \"line 2\", linestyle=\"--\")\n",
    "# plt.plot(x, np.sin(x), label = \"curve 1\", linestyle=\"-.\")\n",
    "# plt.plot(x, np.cos(x), label = \"curve 2\", linestyle=\":\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(norm_l, nmi_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(norm_l, ari_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(norm_l, acc_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Perturbation Norm\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('spice_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, label = \"line 1\", linestyle=\"-\")\n",
    "# plt.plot(y, x, label = \"line 2\", linestyle=\"--\")\n",
    "# plt.plot(x, np.sin(x), label = \"curve 1\", linestyle=\"-.\")\n",
    "# plt.plot(x, np.cos(x), label = \"curve 2\", linestyle=\":\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(norm_l, nmi_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(norm_l, ari_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(norm_l, acc_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Perturbation Norm\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('spice_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
