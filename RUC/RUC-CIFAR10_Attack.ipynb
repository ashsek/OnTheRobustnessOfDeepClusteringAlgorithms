{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import copy\n",
    "import datasets\n",
    "import models\n",
    "from lib.utils import AverageMeter\n",
    "from lib.protocols import *\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from randaugment import RandAugmentMC\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    global args\n",
    "    parser = argparse.ArgumentParser(description='config for RUC')\n",
    "    parser.add_argument('--lr', default=0.01, type=float, metavar='LR', help='initial learning rate')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--weight_decay', '--wd', default=5e-4, type=float, metavar='W', help='weight decay')\n",
    "    parser.add_argument('--epochs', default=200, type=int, help='max epoch per round. (default: 200)')\n",
    "    parser.add_argument('--batch_size', default=256, type=int, metavar='B', help='training batch size')\n",
    "    parser.add_argument('--s_thr', default=0.99, type=float, help='confidence sampling threshold')\n",
    "    parser.add_argument('--n_num', default=100, type=float, help='the number of neighbor')\n",
    "    parser.add_argument('--o_model', default='checkpoint/selflabel_cifar-10.pth.tar', type=str, help='original model path')\n",
    "    parser.add_argument('--e_model', default='checkpoint/simclr_cifar-10.pth.tar', type=str, help='embedding model save path')\n",
    "    parser.add_argument('--seed', default=1567010775, type=int, help='random seed')\n",
    "    \n",
    "    args = parser.parse_args(args=[])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, smoothing=0.0):\n",
    "        super(LabelSmoothLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        log_prob = F.log_softmax(input, dim=-1)\n",
    "        weight = input.new_ones(input.size()) * \\\n",
    "            self.smoothing / (input.size(-1) - 1.)\n",
    "        weight.scatter_(-1, target.unsqueeze(-1).long(), (1. - self.smoothing))\n",
    "        loss = (-weight * log_prob).sum(dim=-1).mean()\n",
    "        return loss\n",
    "    \n",
    "LSloss = LabelSmoothLoss(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_rampup(current, rampup_length=200):\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip((current) / rampup_length, 0.1, 1.0)\n",
    "        return float(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class criterion_rb(object):\n",
    "    def __call__(self, outputs_x, targets_x, outputs_u, targets_u, epoch):\n",
    "        # Clean sample Loss\n",
    "        probs_u = torch.softmax(outputs_u, dim=1)\n",
    "        Lx = -torch.mean(torch.sum(F.log_softmax(outputs_x, dim=1) * targets_x, dim=1))\n",
    "        Lu = 25*torch.mean((probs_u - targets_u)**2)\n",
    "        Lu = linear_rampup(epoch) * Lu\n",
    "        return Lx, Lu\n",
    "\n",
    "def get_threshold(current):\n",
    "    return 0.9 + 0.02*int(current / 40)\n",
    "        \n",
    "def extract_metric(net, p_label, evalloader, n_num):\n",
    "    net.eval()\n",
    "    feature_bank = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs1 , _, _, _, indexes) in enumerate(evalloader):\n",
    "            out = net(inputs1.cuda())\n",
    "            feature_bank.append(out)\n",
    "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
    "        sim_indices_list = []\n",
    "        for batch_idx, (inputs1 , _, _, _, indexes) in enumerate(evalloader):\n",
    "            out = net(inputs1.cuda(non_blocking=True))\n",
    "            sim_matrix = torch.mm(out, feature_bank)\n",
    "            _, sim_indices = sim_matrix.topk(k=n_num, dim=-1)\n",
    "            sim_indices_list.append(sim_indices)\n",
    "        feature_labels = p_label.cuda()\n",
    "        first = True\n",
    "        count = 0\n",
    "        clean_num = 0\n",
    "        correct_num = 0\n",
    "        for batch_idx, (inputs1 , _, _, targets, indexes) in enumerate(evalloader):\n",
    "            labels = p_label[indexes].cuda().long()\n",
    "            sim_indices = sim_indices_list[count]\n",
    "            sim_labels = torch.gather(feature_labels.expand(inputs1.size(0), -1), dim=-1, index=sim_indices)\n",
    "            # counts for each class\n",
    "            one_hot_label = torch.zeros(inputs1.size(0) * sim_indices.size(1), 10).cuda()\n",
    "            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1).long(), value=1.0)\n",
    "            pred_scores = torch.sum(one_hot_label.view(inputs1.size(0), -1, 10), dim=1)\n",
    "            count += 1\n",
    "            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "            prob, _ = torch.max(F.softmax(pred_scores, dim=-1), 1)   \n",
    "            # Check whether prediction and current label are same\n",
    "            noisy_label = labels\n",
    "            s_idx1 = (pred_labels[:, :1].float() == labels.unsqueeze(dim=-1).float()).any(dim=-1).float()\n",
    "            s_idx = (s_idx1 == 1.0)\n",
    "            clean_num += labels[s_idx].shape[0]\n",
    "            correct_num += torch.sum((labels[s_idx].float() == targets[s_idx].cuda().float())).item()\n",
    "\n",
    "            if first:\n",
    "                prob_set = prob\n",
    "                pred_same_label_set = s_idx\n",
    "                first = False\n",
    "            else:\n",
    "                prob_set = torch.cat((prob_set, prob), dim = 0)\n",
    "                pred_same_label_set = torch.cat((pred_same_label_set, s_idx), dim = 0)\n",
    "\n",
    "        print(correct_num, clean_num)\n",
    "        return pred_same_label_set\n",
    "            \n",
    "def extract_confidence(net, p_label, evalloader, threshold):\n",
    "    net.eval()\n",
    "    devide = torch.tensor([]).cuda()\n",
    "    clean_num = 0\n",
    "    correct_num = 0\n",
    "    for batch_idx, (inputs1, _, _, targets, indexes) in enumerate(evalloader):\n",
    "        inputs1, targets = inputs1.cuda(), targets.cuda().float()\n",
    "        labels = p_label[indexes].float()\n",
    "        logits = net(inputs1)\n",
    "        prob = torch.softmax(logits.detach_(), dim=-1)\n",
    "        max_probs, _ = torch.max(prob, dim=-1)\n",
    "        mask = max_probs.ge(threshold).float()\n",
    "        devide = torch.cat([devide, mask])\n",
    "        s_idx = (mask == 1)\n",
    "        clean_num += labels[s_idx].shape[0]\n",
    "        correct_num += torch.sum((labels[s_idx] == targets[s_idx])).item()\n",
    "    \n",
    "    print(correct_num, clean_num)\n",
    "    return devide\n",
    "\n",
    "def extract_hybrid(devide1, devide2, p_label, evalloader):\n",
    "    devide = (devide1.float() + devide2.float() == 2)\n",
    "    clean_num = 0\n",
    "    correct_num = 0\n",
    "    for batch_idx, (inputs1, _, _, targets, indexes) in enumerate(evalloader):\n",
    "        inputs1, targets = inputs1.cuda(), targets.cuda().float()\n",
    "        labels = p_label[indexes].float()\n",
    "        mask = devide[indexes]\n",
    "        s_idx = (mask == 1)\n",
    "        clean_num += labels[s_idx].shape[0]\n",
    "        correct_num += torch.sum((labels[s_idx] == targets[s_idx])).item()\n",
    "    \n",
    "    print(correct_num, clean_num)\n",
    "    return devide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(args):\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=32, scale=(0.2,1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.CenterCrop(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "    \n",
    "    transform_strong = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=32, scale=(0.2,1.)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            RandAugmentMC(n=2, m=2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "    trainset = datasets.CIFAR10RUC(root=\"./data\", transform=transform_test, transform2 = transform_train, transform3 = transform_train, transform4 = transform_strong, download=True)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
    "    testset = datasets.CIFAR10RUC(root=\"./data\",transform=transform_test, transform2 = transform_test, transform3 = transform_test,  download=True)\n",
    "    evalloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n",
    "        \n",
    "    return trainset, trainloader, testset, evalloader, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(args, optimizer, epoch):\n",
    "    # cosine learning rate schedule\n",
    "    lr = args.lr\n",
    "    lr *= 0.5 * (1. + math.cos(math.pi * epoch / args.epochs))\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch, net, net2, trainloader, optimizer, criterion_rb, devide, p_label, conf):\n",
    "    train_loss = AverageMeter()\n",
    "    net.train()\n",
    "    net2.train()\n",
    "    \n",
    "    num_iter = (len(trainloader.dataset)//args.batch_size)+1\n",
    "    # adjust learning rate\n",
    "    adjust_learning_rate(args, optimizer, epoch)  \n",
    "    optimizer.zero_grad()\n",
    "    correct_u = 0\n",
    "    unsupervised = 0\n",
    "    conf_self = torch.zeros(50000)\n",
    "    for batch_idx, (inputs1 , inputs2, inputs3, inputs4, targets, indexes) in enumerate(trainloader):\n",
    "        inputs1, inputs2, inputs3, inputs4, targets = inputs1.float().cuda(), inputs2.float().cuda(), inputs3.float().cuda(), inputs4.float().cuda(), targets.cuda().long()\n",
    "        s_idx = (devide[indexes] == 1)\n",
    "        u_idx = (devide[indexes] == 0)\n",
    "        labels = p_label[indexes].cuda().long()\n",
    "        labels_x = torch.tensor(p_label[indexes][s_idx]).squeeze().long().cpu()\n",
    "        target_x = torch.zeros(labels_x.shape[0], 10).scatter_(1, labels_x.view(-1,1), 1).float().cuda()\n",
    "        \n",
    "        logit_o, logit_w1, logit_w2, logit_s = net(inputs1), net(inputs2), net(inputs3), net(inputs4)\n",
    "        logit_s = logit_s[s_idx]\n",
    "        max_probs, _ = torch.max(torch.softmax(logit_o, dim=1), dim=-1)\n",
    "        conf_self[indexes] = max_probs.detach().cpu()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # compute guessed labels of unlabel samples\n",
    "            outputs_u11 = logit_w1[u_idx]\n",
    "            outputs_u21  = logit_w2[u_idx]\n",
    "            logit_o2 = net2(inputs1)\n",
    "            logit_w12 = net2(inputs2)\n",
    "            logit_w22 = net2(inputs3)\n",
    "            outputs_u12 = logit_w12[u_idx]\n",
    "            outputs_u22  = logit_w22[u_idx]\n",
    "            pu = (torch.softmax(outputs_u11, dim=1) + torch.softmax(outputs_u21, dim=1) + torch.softmax(outputs_u12, dim=1) + torch.softmax(outputs_u22, dim=1)) / 4\n",
    "            ptu = pu**(1/0.5) # temparature sharpening\n",
    "            target_u = ptu / ptu.sum(dim=1, keepdim=True) # normalize\n",
    "            target_u = target_u.detach().float() \n",
    "            \n",
    "            px = torch.softmax(logit_o2[s_idx], dim=1) #+ torch.softmax(logit_w22[s_idx], dim=1)) / 2\n",
    "            w_x = conf[indexes][s_idx]\n",
    "            w_x = w_x.view(-1,1).float().cuda() \n",
    "            px = (1-w_x)*target_x + w_x*px              \n",
    "            ptx = px**(1/0.5) # temparature sharpening           \n",
    "            target_x = ptx / ptx.sum(dim=1, keepdim=True) # normalize           \n",
    "            target_x = target_x.detach().float()      \n",
    "            \n",
    "            if logit_o2[u_idx].shape[0] > 0: \n",
    "                max_probs, targets_u1 = torch.max(torch.softmax(logit_o[u_idx], dim=1), dim=-1)    \n",
    "                mask_u = max_probs.ge(0.99).float()\n",
    "                u_idx2 = (mask_u == 1)\n",
    "                unsupervised += torch.sum(mask_u).item()\n",
    "                correct_u += torch.sum((targets_u1[u_idx2] == targets[u_idx][u_idx2])).item()\n",
    "                update = indexes[u_idx][u_idx2]\n",
    "                devide[update] = True\n",
    "                p_label[update] = targets_u1[u_idx2].float()\n",
    "        \n",
    "        \n",
    "        l = np.random.beta(4.0, 4.0)        \n",
    "        l = max(l, 1-l)\n",
    "        \n",
    "        all_inputs = torch.cat([inputs2[s_idx], inputs3[s_idx], inputs2[u_idx], inputs3[u_idx]],dim=0)\n",
    "        all_targets = torch.cat([target_x, target_x, target_u, target_u], dim=0)\n",
    "        idx = torch.randperm(all_inputs.size(0))\n",
    "\n",
    "        input_a, input_b = all_inputs, all_inputs[idx]\n",
    "        target_a, target_b = all_targets, all_targets[idx]\n",
    "        \n",
    "        mixed_input = l * input_a + (1 - l) * input_b        \n",
    "        mixed_target = l * target_a + (1 - l) * target_b\n",
    "                \n",
    "        logits = net(mixed_input)\n",
    "        batch_size = target_x.shape[0]\n",
    "        \n",
    "        Lx, Lu = criterion_rb(logits[:batch_size*2], mixed_target[:batch_size*2], logits[batch_size*2:], mixed_target[batch_size*2:], epoch+batch_idx/num_iter)\n",
    "        total_loss = Lx + Lu + LSloss(logit_s, labels_x.cuda())\n",
    "        \n",
    "        total_loss.backward()\n",
    "        train_loss.update(total_loss.item(), inputs2.size(0))\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch: [{epoch}][{elps_iters}/{tot_iters}] '\n",
    "                  'Train loss: {train_loss.val:.4f} ({train_loss.avg:.4f}) '.format(\n",
    "                      epoch=epoch, elps_iters=batch_idx,tot_iters=len(trainloader), \n",
    "                      train_loss=train_loss))\n",
    "    conf_self = (conf_self - conf_self.min()) / (conf_self.max() - conf_self.min())\n",
    "    \n",
    "    return train_loss.avg, devide, p_label, conf_self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = config()\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trainset, trainloader, testset, evalloader, class_num = preprocess(args)\n",
    "net = models.ClusteringModel(models.__dict__['Resnet_CIFAR'](), class_num)\n",
    "net2 = copy.deepcopy(net)\n",
    "net_uc = copy.deepcopy(net)\n",
    "net_embd = models.ContrastiveModel(models.__dict__['Resnet_CIFAR']())\n",
    "\n",
    "try:\n",
    "    state_dict = torch.load(args.o_model)\n",
    "    state_dict2 = torch.load(args.e_model)\n",
    "    net_uc.load_state_dict(state_dict)\n",
    "    net_embd.load_state_dict(state_dict2, strict = True)\n",
    "    net.load_state_dict(state_dict, strict = False)\n",
    "    net2.load_state_dict(state_dict, strict = False)\n",
    "    net.cluster_head = nn.ModuleList([nn.Linear(512, class_num) for _ in range(1)])\n",
    "    net2.cluster_head = nn.ModuleList([nn.Linear(512, class_num) for _ in range(1)])\n",
    "except:\n",
    "    print(\"Check Model Directory!\")\n",
    "    exit(0)\n",
    "\n",
    "if args.device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    net2 = torch.nn.DataParallel(net2, device_ids=range(torch.cuda.device_count()))\n",
    "    net_uc = torch.nn.DataParallel(net_uc, device_ids=range(torch.cuda.device_count()))\n",
    "    net_embd = torch.nn.DataParallel(net_embd, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net.to(args.device)\n",
    "net2.to(args.device)\n",
    "net_uc.to(args.device)\n",
    "net_embd.to(args.device)\n",
    "\n",
    "optimizer1 = torch.optim.SGD(net.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=True)\n",
    "optimizer2 = torch.optim.SGD(net2.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=True)\n",
    "criterion = criterion_rb()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Pseudo Label\n",
    "acc_uc, p_label= test(net_uc, evalloader, args.device, class_num)\n",
    "print(acc_uc)\n",
    "devide1 = extract_confidence(net_uc, p_label, evalloader, args.s_thr)\n",
    "devide2 = extract_metric(net_embd, p_label, evalloader, args.n_num)\n",
    "devide = extract_hybrid(devide1, devide2, p_label, evalloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('./checkpoint/cifar10_ruc.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(state['net1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.load_state_dict(state['net2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc(net, net2, evalloader, args.device, class_num)\n",
    "print(\"accuracy: {}\\n\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN GAN ON IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gan_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "image_nc=3\n",
    "epochs = 60\n",
    "batch_size = 256\n",
    "BOX_MIN = 0\n",
    "BOX_MAX = 1\n",
    "model_num_labels = 10\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = gan_attack.GAN_Attack(device, net, net2, model_num_labels, image_nc, BOX_MIN, BOX_MAX, 'cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Holding the original output object. i.e. console out\n",
    "orig_stdout = sys.stdout\n",
    "\n",
    "# Opening the file to write file deletion logs.\n",
    "f = open('outgan_train-every256.txt', 'a+')\n",
    "\n",
    "# Changing standard out to file out. \n",
    "sys.stdout = f\n",
    "# This will write to the file. \n",
    "print(\"xyz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "advGAN.train(evalloader, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the file.\n",
    "f.close()\n",
    "\n",
    "\n",
    "# replacing the original output format to stdout.\n",
    "sys.stdout = orig_stdout\n",
    "\n",
    "# This will print onto the console.\n",
    "print(\"xyz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_2ncifar10_epoch_600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.25, 'CIFAR10')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc_adv_save(net, net2, evalloader, args.device, class_num, pretrained_G, 0.25, 'CIFAR10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.1, 'CIFAR10')\n",
    "print(\"accuracy: {}\\n\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "\n",
    "MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "STD = torch.tensor([0.2023, 0.1994, 0.2010]).cuda()\n",
    "\n",
    "# x = normalized_img * STD[:, None, None] + MEAN[:, None, None]\n",
    "\n",
    "def pp(images, labels):\n",
    "    MEAN = torch.tensor([0.485, 0.456, 0.406]).cuda()\n",
    "    STD = torch.tensor([0.2023, 0.1994, 0.2010]).cuda()\n",
    "    print(type(images[0]), type(labels))\n",
    "    print(images.shape)\n",
    "#     w = \n",
    "#     h = 10\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    columns = 11\n",
    "    rows = 12\n",
    "    for i in range(35):\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        img = images[i]\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5   # unnormalize\n",
    "        img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "#         img = (img * 255).astype(np.uint8)\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5 \n",
    "#         npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        \n",
    "#         plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "        plt.imshow(img.transpose(1, 2, 0))\n",
    "#         plt.imshow(npimg)\n",
    "#         plt.title('#{}: {}'.format(i, labels[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printall(evalloader):\n",
    "    for batch_idx, (inputs, _, _, targets, indexes) in enumerate(evalloader):\n",
    "        batchSize = inputs.size(0)\n",
    "        targets, inputs = targets.to(device), inputs.to(device)\n",
    "        perturbation = pretrained_G(inputs)\n",
    "        perturbation = torch.clamp(perturbation, -0.25, 0.25)\n",
    "        adv_imgs = perturbation + inputs\n",
    "    #     print(inputs[0][0])\n",
    "    #     print(adv_imgs[0][0])\n",
    "        pp(inputs, targets)\n",
    "        pp(adv_imgs, targets)\n",
    "        pp(perturbation, targets)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmi_l = []\n",
    "ari_l = []\n",
    "for j in range(10):\n",
    "    acc = test_ruc_cls(net, net2, evalloader, args.device, class_num, pretrained_G, 0.25, 'CIFAR10', j)\n",
    "    nmi_l.append(acc[0][-2])\n",
    "    ari_l.append(acc[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "classes = [str(i) for i in range(10)]\n",
    "plt.plot(classes, nmi_l)\n",
    "print(nmi_l)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(classes, ari_l)\n",
    "print(ari_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test_ruc_cls(net, net2, evalloader, args.device, class_num, pretrained_G, 0.25, 'CIFAR10', 3)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.5, 'CIFAR10')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_MICE_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.5, 'CIFAR10')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_NNM_cifar-10_epoch_570.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.2, 'CIFAR10')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trasnfer scan\n",
    "\n",
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_SCAN_cifar-10_epoch_1200.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.2, 'CIFAR10')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trasnfer spice\n",
    "\n",
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_SPICE_cifar-10_epoch600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.2, 'CIFAR10')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# additional Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_2ncifar10_epoch_600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list, norm = test_ruc_adv_norm(net, net2, evalloader, args.device, class_num, pretrained_G, 0.25, 'CIFAR10')\n",
    "acc2, nmi, ari = acc[-3], acc[-2], acc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc2, nmi, ari, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "clamp = [0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "#     acc2, mice_pi_acc, nmi, ari, norm = get_MiCE_adv_performance_norm(model, model_ema, elbo, full_loader, n_data, n_class, clamping=j)\n",
    "    acc, p_list, norm = test_ruc_adv_norm(net, net2, evalloader, args.device, class_num, pretrained_G, j, 'CIFAR10')\n",
    "    acc2, nmi, ari = acc[-3], acc[-2], acc[-1]\n",
    "#         print(clustering_stats)\n",
    "    \n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc2))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, label = \"line 1\", linestyle=\"-\")\n",
    "# plt.plot(y, x, label = \"line 2\", linestyle=\"--\")\n",
    "# plt.plot(x, np.sin(x), label = \"curve 1\", linestyle=\"-.\")\n",
    "# plt.plot(x, np.cos(x), label = \"curve 2\", linestyle=\":\")\n",
    "\n",
    "plt.plot(norm_l, nmi_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(norm_l, ari_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(norm_l, acc_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Perturbation Norm\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('ruc_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## same acc formuala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list, norm = test_ruc_adv_norm(net, net2, evalloader, args.device, class_num, pretrained_G, 0.25, 'CIFAR10')\n",
    "acc2, nmi, ari = acc[-3], acc[-2], acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2, nmi, ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "clamp = [0, 0.25, 1.0]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "#     acc2, mice_pi_acc, nmi, ari, norm = get_MiCE_adv_performance_norm(model, model_ema, elbo, full_loader, n_data, n_class, clamping=j)\n",
    "    acc, p_list, norm = test_ruc_adv_norm(net, net2, evalloader, args.device, class_num, pretrained_G, j, 'CIFAR10')\n",
    "    acc2, nmi, ari = acc[-3], acc[-2], acc[-1]\n",
    "#         print(clustering_stats)\n",
    "    \n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc2))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
