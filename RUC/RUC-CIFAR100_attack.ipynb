{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original RUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import copy\n",
    "import datasets\n",
    "import models\n",
    "from lib.utils import AverageMeter\n",
    "from lib.protocols import *\n",
    "import math\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "from randaugment import RandAugmentMC\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    global args\n",
    "    parser = argparse.ArgumentParser(description='config for RUC')\n",
    "    parser.add_argument('--lr', default=0.01, type=float, metavar='LR', help='initial learning rate')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--weight_decay', '--wd', default=5e-4, type=float, metavar='W', help='weight decay')\n",
    "    parser.add_argument('--epochs', default=200, type=int, help='max epoch per round. (default: 200)')\n",
    "    parser.add_argument('--batch_size', default=256, type=int, metavar='B', help='training batch size')\n",
    "    parser.add_argument('--s_thr', default=0.99, type=float, help='confidence sampling threshold')\n",
    "    parser.add_argument('--n_num', default=100, type=float, help='the number of neighbor')\n",
    "    parser.add_argument('--o_model', default='checkpoint/selflabel_cifar-20.pth.tar', type=str, help='original model path')\n",
    "    parser.add_argument('--e_model', default='checkpoint/simclr_cifar-20.pth.tar', type=str, help='embedding model save path')\n",
    "    parser.add_argument('--seed', default=1567010775, type=int, help='random seed')\n",
    "    \n",
    "    args = parser.parse_args([])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, smoothing=0.0):\n",
    "        super(LabelSmoothLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        log_prob = F.log_softmax(input, dim=-1)\n",
    "        weight = input.new_ones(input.size()) * \\\n",
    "            self.smoothing / (input.size(-1) - 1.)\n",
    "        weight.scatter_(-1, target.unsqueeze(-1).long(), (1. - self.smoothing))\n",
    "        loss = (-weight * log_prob).sum(dim=-1).mean()\n",
    "        return loss\n",
    "    \n",
    "LSloss = LabelSmoothLoss(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(current):\n",
    "    return 0.9 + 0.02*int(current / 40)\n",
    "\n",
    "def linear_rampup(current, rampup_length=200):\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip((current) / rampup_length, 0.1, 1.0)\n",
    "        return float(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class criterion_rb(object):\n",
    "    def __call__(self, outputs_x, targets_x, outputs_u, targets_u, epoch):\n",
    "        # Clean sample Loss\n",
    "        probs_u = torch.softmax(outputs_u, dim=1)\n",
    "        Lx = -torch.mean(torch.sum(F.log_softmax(outputs_x, dim=1) * targets_x, dim=1))\n",
    "        Lu = 100*torch.mean((probs_u - targets_u)**2)\n",
    "        Lu = linear_rampup(epoch) * Lu\n",
    "        return Lx, Lu\n",
    "            \n",
    "def extract_metric(net, p_label, evalloader, n_num):\n",
    "    net.eval()\n",
    "    feature_bank = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs1 , _, _, _, indexes) in enumerate(evalloader):\n",
    "            out = net(inputs1.cuda())\n",
    "            feature_bank.append(out)\n",
    "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
    "        sim_indices_list = []\n",
    "        for batch_idx, (inputs1 , _, _, _, indexes) in enumerate(evalloader):\n",
    "            out = net(inputs1.cuda(non_blocking=True))\n",
    "            sim_matrix = torch.mm(out, feature_bank)\n",
    "            _, sim_indices = sim_matrix.topk(k=n_num, dim=-1)\n",
    "            sim_indices_list.append(sim_indices)\n",
    "        feature_labels = p_label.cuda()\n",
    "        first = True\n",
    "        count = 0\n",
    "        clean_num = 0\n",
    "        correct_num = 0\n",
    "        for batch_idx, (inputs1 , _, _, targets, indexes) in enumerate(evalloader):\n",
    "            labels = p_label[indexes].cuda().long()\n",
    "            sim_indices = sim_indices_list[count]\n",
    "            sim_labels = torch.gather(feature_labels.expand(inputs1.size(0), -1), dim=-1, index=sim_indices)\n",
    "            # counts for each class\n",
    "            one_hot_label = torch.zeros(inputs1.size(0) * sim_indices.size(1), 20).cuda()\n",
    "            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1).long(), value=1.0)\n",
    "            pred_scores = torch.sum(one_hot_label.view(inputs1.size(0), -1, 20), dim=1)\n",
    "            count += 1\n",
    "            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "            prob, _ = torch.max(F.softmax(pred_scores, dim=-1), 1)     \n",
    "            # Check whether prediction and current label are same\n",
    "            noisy_label = labels\n",
    "            s_idx1 = (pred_labels[:, :1].float() == labels.unsqueeze(dim=-1).float()).any(dim=-1).float()\n",
    "            s_idx = (s_idx1 == 1.0)\n",
    "            clean_num += labels[s_idx].shape[0]\n",
    "            correct_num += torch.sum((labels[s_idx].float() == targets[s_idx].cuda().float())).item()\n",
    "\n",
    "            if first:\n",
    "                prob_set = prob\n",
    "                pred_same_label_set = s_idx\n",
    "                first = False\n",
    "            else:\n",
    "                prob_set = torch.cat((prob_set, prob), dim = 0)\n",
    "                pred_same_label_set = torch.cat((pred_same_label_set, s_idx), dim = 0)\n",
    "\n",
    "        print(correct_num, clean_num)\n",
    "        return pred_same_label_set\n",
    "            \n",
    "def extract_confidence(net, p_label, evalloader, threshold):\n",
    "    net.eval()\n",
    "    devide = torch.tensor([]).cuda()\n",
    "    clean_num = 0\n",
    "    correct_num = 0\n",
    "    for batch_idx, (inputs1, _, _, targets, indexes) in enumerate(evalloader):\n",
    "        inputs1, targets = inputs1.cuda(), targets.cuda().float()\n",
    "        labels = p_label[indexes].float()\n",
    "        logits = net(inputs1)\n",
    "        prob = torch.softmax(logits.detach_(), dim=-1)\n",
    "        max_probs, _ = torch.max(prob, dim=-1)\n",
    "        mask = max_probs.ge(threshold).float()\n",
    "        devide = torch.cat([devide, mask])\n",
    "        s_idx = (mask == 1)\n",
    "        clean_num += labels[s_idx].shape[0]\n",
    "        correct_num += torch.sum((labels[s_idx] == targets[s_idx])).item()\n",
    "    \n",
    "    print(correct_num, clean_num)\n",
    "    return devide\n",
    "\n",
    "def extract_hybrid(devide1, devide2, p_label, evalloader):\n",
    "    devide = (devide1.float() + devide2.float() == 2)\n",
    "    clean_num = 0\n",
    "    correct_num = 0\n",
    "    for batch_idx, (inputs1, _, _, targets, indexes) in enumerate(evalloader):\n",
    "        inputs1, targets = inputs1.cuda(), targets.cuda().float()\n",
    "        labels = p_label[indexes].float()\n",
    "        mask = devide[indexes]\n",
    "        s_idx = (mask == 1)\n",
    "        clean_num += labels[s_idx].shape[0]\n",
    "        correct_num += torch.sum((labels[s_idx] == targets[s_idx])).item()\n",
    "    \n",
    "    print(correct_num, clean_num)\n",
    "    return devide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(args):\n",
    "    mean = [0.5071, 0.4867, 0.4408]\n",
    "    std = [0.2675, 0.2565, 0.2761]\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=32, scale=(0.2,1.)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.CenterCrop(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "    \n",
    "    transform_strong = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=32, scale=(0.2,1.)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            RandAugmentMC(n=2, m=2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "    trainset = datasets.CIFAR20RUC(root=\"./data\", transform=transform_test, transform2 = transform_train, transform3 = transform_train, transform4 = transform_strong, download=True)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
    "    testset = datasets.CIFAR20RUC(root=\"./data\",transform=transform_test, transform2 = transform_test, transform3 = transform_test,  download=False)\n",
    "    evalloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return trainset, trainloader, testset, evalloader, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(args, optimizer, epoch):\n",
    "    # cosine learning rate schedule\n",
    "    lr = args.lr\n",
    "    lr *= 0.5 * (1. + math.cos(math.pi * epoch / args.epochs))\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = config()\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trainset, trainloader, testset, evalloader, class_num = preprocess(args)\n",
    "net = models.ClusteringModel(models.__dict__['Resnet_CIFAR'](), class_num)\n",
    "net2 = copy.deepcopy(net)\n",
    "net_uc = copy.deepcopy(net)\n",
    "net_embd = models.ContrastiveModel(models.__dict__['Resnet_CIFAR']())\n",
    "\n",
    "try:\n",
    "    state_dict = torch.load(args.o_model)\n",
    "    state_dict2 = torch.load(args.e_model)\n",
    "    net_uc.load_state_dict(state_dict)\n",
    "    net_embd.load_state_dict(state_dict2, strict = True)\n",
    "    net.load_state_dict(state_dict, strict = False)\n",
    "    net2.load_state_dict(state_dict, strict = False)\n",
    "    net.cluster_head = nn.ModuleList([nn.Linear(512, class_num) for _ in range(1)])\n",
    "    net2.cluster_head = nn.ModuleList([nn.Linear(512, class_num) for _ in range(1)])\n",
    "except:\n",
    "    print(\"Check Model Directory!\")\n",
    "    exit(0)\n",
    "\n",
    "if args.device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    net2 = torch.nn.DataParallel(net2, device_ids=range(torch.cuda.device_count()))\n",
    "    net_uc = torch.nn.DataParallel(net_uc, device_ids=range(torch.cuda.device_count()))\n",
    "    net_embd = torch.nn.DataParallel(net_embd, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    net.to(args.device)\n",
    "    net2.to(args.device)\n",
    "    net_uc.to(args.device)\n",
    "    net_embd.to(args.device)\n",
    "    \n",
    "    optimizer1 = torch.optim.SGD(net.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=True)\n",
    "    optimizer2 = torch.optim.SGD(net2.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=True)\n",
    "    criterion = criterion_rb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Pseudo Label\n",
    "acc_uc, p_label= test(net_uc, evalloader, args.device, class_num)\n",
    "print(acc_uc)\n",
    "devide1 = extract_confidence(net_uc, p_label, evalloader, args.s_thr)\n",
    "devide2 = extract_metric(net_embd, p_label, evalloader, args.n_num)\n",
    "devide = extract_hybrid(devide1, devide2, p_label, evalloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('./checkpoint/cifar20_ruc.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(state['net1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.load_state_dict(state['net2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc(net, net2, evalloader, args.device, class_num)\n",
    "print(\"accuracy: {}\\n\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN GAN ON IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gan_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "image_nc=3\n",
    "epochs = 60\n",
    "batch_size = 256\n",
    "BOX_MIN = 0\n",
    "BOX_MAX = 1\n",
    "model_num_labels = 10\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = gan_attack.GAN_Attack(device, net, net2, model_num_labels, image_nc, BOX_MIN, BOX_MAX, 'cifar20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Holding the original output object. i.e. console out\n",
    "orig_stdout = sys.stdout\n",
    "\n",
    "# Opening the file to write file deletion logs.\n",
    "f = open('outgan_train256_c_100.txt', 'a+')\n",
    "\n",
    "# Changing standard out to file out. \n",
    "sys.stdout = f\n",
    "# This will write to the file. \n",
    "print(\"xyz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "GAN.train(evalloader, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the file.\n",
    "f.close()\n",
    "\n",
    "\n",
    "# replacing the original output format to stdout.\n",
    "sys.stdout = orig_stdout\n",
    "\n",
    "# This will print onto the console.\n",
    "print(\"xyz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls\n",
    "print('xyz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_cifar20_epoch_300.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.15, 'CIFAR20')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc, p_list = test_ruc_adv_save(net, net2, evalloader, args.device, class_num, pretrained_G, 0.15, 'CIFAR20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After attack: 19.246, 0.17363851715493359, 0.019951311652274734"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Accuracy, NMI, ARI: 54.33, 0.5515355838106161, 0.3870472855140499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "\n",
    "MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "STD = torch.tensor([0.2023, 0.1994, 0.2010]).cuda()\n",
    "\n",
    "# x = normalized_img * STD[:, None, None] + MEAN[:, None, None]\n",
    "\n",
    "def pp(images, labels):\n",
    "    MEAN = torch.tensor([0.4914, 0.4822, 0.4465]).cuda()\n",
    "    STD = torch.tensor([0.2023, 0.1994, 0.2010]).cuda()\n",
    "    print(type(images[0]), type(labels))\n",
    "    print(images.shape)\n",
    "#     w = \n",
    "#     h = 10\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    columns = 11\n",
    "    rows = 12\n",
    "    for i in range(35):\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        img = images[i]\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5   # unnormalize\n",
    "        img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "#         img = (img * 255).astype(np.uint8)\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5 \n",
    "#         npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        \n",
    "#         plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "        plt.imshow(img.transpose(1, 2, 0))\n",
    "#         plt.imshow(npimg)\n",
    "#         plt.title('#{}: {}'.format(i, labels[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (inputs, _, _, targets, indexes) in enumerate(evalloader):\n",
    "    batchSize = inputs.size(0)\n",
    "    targets, inputs = targets.to(device), inputs.to(device)\n",
    "    perturbation = pretrained_G(inputs)\n",
    "    perturbation = torch.clamp(perturbation, -0.15, 0.15)\n",
    "    adv_imgs = perturbation + inputs\n",
    "#     print(inputs[0])\n",
    "    pp(inputs, targets)\n",
    "    pp(adv_imgs, targets)\n",
    "    pp(perturbation, targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_cc_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.15, 'CIFAR20')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_NNM_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.15, 'CIFAR20')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_SCAN_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.15, 'CIFAR20')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_MICE_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.15, 'CIFAR20')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_SPICE_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "acc, p_list = test_ruc_adv(net, net2, evalloader, args.device, class_num, pretrained_G, 0.15, 'CIFAR20')\n",
    "print(\"accuracy: {}\\n\".format(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "device = 'cuda'\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_cifar20_epoch_300.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "clamp = [0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "#     acc2, mice_pi_acc, nmi, ari, norm = get_MiCE_adv_performance_norm(model, model_ema, elbo, full_loader, n_data, n_class, clamping=j)\n",
    "    acc, p_list, norm = test_ruc_adv_norm(net, net2, evalloader, args.device, class_num, pretrained_G, j, 'CIFAR20')\n",
    "    acc2, nmi, ari = acc[-3], acc[-2], acc[-1]\n",
    "#         print(clustering_stats)\n",
    "    \n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc2))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc2/100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, label = \"line 1\", linestyle=\"-\")\n",
    "# plt.plot(y, x, label = \"line 2\", linestyle=\"--\")\n",
    "# plt.plot(x, np.sin(x), label = \"curve 1\", linestyle=\"-.\")\n",
    "# plt.plot(x, np.cos(x), label = \"curve 2\", linestyle=\":\")\n",
    "\n",
    "plt.plot(norm_l, nmi_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(norm_l, ari_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(norm_l, acc_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Perturbation Norm\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('ruc_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "# clamp = [0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "clamp = [0, 0.15, 1]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "#     acc2, mice_pi_acc, nmi, ari, norm = get_MiCE_adv_performance_norm(model, model_ema, elbo, full_loader, n_data, n_class, clamping=j)\n",
    "    acc, p_list, norm = test_ruc_adv_norm(net, net2, evalloader, args.device, class_num, pretrained_G, j, 'CIFAR20')\n",
    "    acc2, nmi, ari = acc[-3], acc[-2], acc[-1]\n",
    "#         print(clustering_stats)\n",
    "    \n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc2))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, label = \"line 1\", linestyle=\"-\")\n",
    "# plt.plot(y, x, label = \"line 2\", linestyle=\"--\")\n",
    "# plt.plot(x, np.sin(x), label = \"curve 1\", linestyle=\"-.\")\n",
    "# plt.plot(x, np.cos(x), label = \"curve 2\", linestyle=\":\")\n",
    "\n",
    "plt.plot(norm_l, nmi_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(norm_l, ari_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(norm_l, acc_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Perturbation Norm\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('ruc_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, p_list, norm = test_ruc_adv_norm(net, net2, evalloader, args.device, class_num, pretrained_G, 0.15, 'CIFAR20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
