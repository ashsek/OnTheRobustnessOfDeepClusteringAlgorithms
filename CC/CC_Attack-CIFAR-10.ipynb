{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original CC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CIFAR-10\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from modules import resnet, network, transform\n",
    "from evaluation import evaluation\n",
    "from torch.utils import data\n",
    "import copy\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, model, device):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j=1\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(x)\n",
    "        c = c.detach()\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        if j:\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            plot_examples(x, y)\n",
    "            torch.cuda.empty_cache()\n",
    "            plot_examples(x, c)\n",
    "            j = 0\n",
    "        labels_vector.extend(y.numpy())\n",
    "#         if step % 20 == 0:\n",
    "#             print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args\n",
    "# general\n",
    "seed= 42\n",
    "workers= 1\n",
    "dataset_dir= \"./dataset\"\n",
    "\n",
    "# train options\n",
    "batch_size= 256\n",
    "image_size= 224\n",
    "start_epoch= 0\n",
    "epoch= 1000\n",
    "dataset= \"CIFAR-10\" # CIFAR-10 / CIFAR-100 / STL-10 / ImageNet-10 / ImageNet-dogs / tiny-ImageNet\n",
    "\n",
    "# model options\n",
    "# resnet= \"ResNet34\" # ResNet18 / ResNet34 / ResNet50\n",
    "feature_dim= 128\n",
    "model_path= \"save/CIFAR-10\"\n",
    "reload= False\n",
    "\n",
    "# loss options\n",
    "learning_rate= 0.0003\n",
    "weight_decay= 0.\n",
    "instance_temperature= 0.5\n",
    "cluster_temperature= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./dataset',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=image_size).test_transform,\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./dataset',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=image_size).test_transform,\n",
    ")\n",
    "dataset = data.ConcatDataset([train_dataset, test_dataset])\n",
    "class_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_examples(images, labels, noise=False, bno=0, adv=False):\n",
    "    print(type(images[0]), type(labels))\n",
    "    \n",
    "    for i in range(min(len(images), 20)):\n",
    "        img = images[i]\n",
    "        npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        npimg = np.clip(npimg, 0, 1)\n",
    "        if not adv:\n",
    "            plt.imsave(f'Images/C10/orig/CC_c10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "        if adv:\n",
    "            plt.imsave(f'Images/C10/adv/CC_c10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)   \n",
    "        if noise:\n",
    "            npimg = npimg / 2 + 0.5 \n",
    "            plt.imsave(f'Images/C10/noise/CC_c10_b{bno}_{i}_noise_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place the original CC model here\n",
    "cc_model = \"./models/checkpoint_1000.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = resnet.get_resnet(\"ResNet34\")\n",
    "model = network.Network(res, feature_dim, class_num)\n",
    "# model_fp = os.path.join(model_path, \"checkpoint_{}.tar\".format(start_epoch))\n",
    "model.load_state_dict(torch.load(cc_model, map_location=device.type)['net'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Creating features from model ###\")\n",
    "X, Y = inference(data_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmi, ari, f, acc = evaluation.evaluate(Y, X) #Y = Label, X = pred\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_attack import GAN_Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "image_nc=3\n",
    "epochs = 60\n",
    "batch_size = 128\n",
    "BOX_MIN = 0\n",
    "BOX_MAX = 1\n",
    "model_num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = GAN_Attack(device, model, model_num_labels, image_nc, BOX_MIN, BOX_MAX, 'cifar-10')\n",
    "# model.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./dataset',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=224, s=0.5),\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./dataset',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=224, s=0.5),\n",
    ")\n",
    "\n",
    "dataset = data.ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "class_num = 10\n",
    "data_loader2 = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Holding the original output object. i.e. console out\n",
    "orig_stdout = sys.stdout\n",
    "\n",
    "# Opening the file to write file deletion logs.\n",
    "f = open('outgan_train.txt', 'a+')\n",
    "\n",
    "# Changing standard out to file out. \n",
    "sys.stdout = f\n",
    "# This will write to the file. \n",
    "print(\"xyz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.train(data_loader2, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the file.\n",
    "f.close()\n",
    "\n",
    "# replacing the original output format to stdout.\n",
    "sys.stdout = orig_stdout\n",
    "\n",
    "# This will print onto the console.\n",
    "print(\"xyz\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "#For adv inference\n",
    "def inference2(loader, model, device, clamp=0.03):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j = 1\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        x = x.to(device)\n",
    "        perturbation = pretrained_G(x)\n",
    "        \n",
    "        \n",
    "        perturbation = torch.clamp(perturbation, -0.15, 0.15)\n",
    "        adv_img = perturbation + x\n",
    "        adv_img = torch.clamp(adv_img, 0, 1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(adv_img)\n",
    "        c = c.detach()\n",
    "        \n",
    "        if j:\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            plot_examples(x,y)\n",
    "            torch.cuda.empty_cache()\n",
    "            plot_examples(adv_img, c)\n",
    "            j = 0\n",
    "\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "#         if step % 20 == 0:\n",
    "#             print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_imgs =  1000\n",
    "def save_examples(images, labels, noise=False, bno=0, adv=False, orig=False):\n",
    "    print(type(images[0]), type(labels))\n",
    "    global count_imgs\n",
    "    \n",
    "    if count_imgs <=0 :\n",
    "        return\n",
    "    for i in range(min(len(images), 20)):\n",
    "        img = images[i]\n",
    "        npimg = img.cpu().detach().numpy()   # convert from tensor\n",
    "        npimg = np.clip(npimg, 0, 1)\n",
    "        count_imgs -= 1\n",
    "        if orig:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/C10/CC/orig/CC_c10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if adv:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/C10/CC/adv/CC_c10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if noise:\n",
    "            npimg = npimg / 2 + 0.5 \n",
    "            plt.imsave(f'Images/C10/CC/noise/CC_c10_b{bno}_{i}_noise_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (x, y) in enumerate(data_loader):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    x = x.to(device)\n",
    "    perturbation = pretrained_G(x)\n",
    "    perturbation = torch.clamp(perturbation, -0.15, 0.15)\n",
    "    adv_x = x + perturbation\n",
    "    \n",
    "    perturbation = perturbation.cpu().detach().numpy()\n",
    "#     print(perturbation[0])\n",
    "    img = perturbation[30] / 2 + 0.5 \n",
    "    \n",
    "    plt.imshow(img.T, cmap=\"gray\")\n",
    "    adv_x = torch.clamp(adv_x, 0, 1)\n",
    "    adv_x = adv_x.cpu().detach().numpy()\n",
    "    \n",
    "    plt.imshow(adv_x[0].T)\n",
    "    plt.imshow(x[0].cpu().detach().numpy().T)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "def inference_save(loader, model, device, clamp=0.03):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j = 1\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        x = x.to(device)\n",
    "        perturbation = pretrained_G(x)\n",
    "        \n",
    "        \n",
    "        perturbation = torch.clamp(perturbation, -0.15, 0.15)\n",
    "        adv_img = perturbation + x\n",
    "        adv_img = torch.clamp(adv_img, 0, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(adv_img)\n",
    "        c = c.detach()\n",
    "        \n",
    "        save_examples(x, y, bno=step, orig=True)\n",
    "        save_examples(adv_img, c.cpu().detach().numpy(), bno=step, adv=True)\n",
    "        save_examples(perturbation, c.cpu().detach().numpy(), bno=step, noise=True)\n",
    "#         raise ValueError\n",
    "        \n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "#         if step % 20 == 0:\n",
    "#             print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "X, Y = inference_save(data_loader, model, 'cuda')\n",
    "\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_MICE_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "X, Y = inference2(data_loader, model, 'cuda', 0.25)\n",
    "\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base NNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_NNM_cifar-10_epoch_570.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "X, Y = inference2(data_loader, model, 'cuda')\n",
    "\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base SCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_SCAN_cifar-10_epoch_1200.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "X, Y = inference2(data_loader, model, 'cuda')\n",
    "\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASE RUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_RUC_cifar-10_epoch600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "X, Y = inference2(data_loader, model, 'cuda')\n",
    "\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_generator_path = './models/transferability/netG_SPICE_cifar-10_epoch600.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "X, Y = inference2(data_loader, model, 'cuda')\n",
    "\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of Pertb Norm vs accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "def inference_n(loader, model, device, clamp=0.05):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j = 1\n",
    "    \n",
    "    perturb_norm = 0.0\n",
    "#     p_n = []\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        x = x.to(device)\n",
    "        perturbation = pretrained_G(x)\n",
    "        perturbation = torch.clamp(perturbation, -clamp, clamp)\n",
    "        perturb_norm += torch.mean(torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1)).to('cpu').item()\n",
    "        \n",
    "        \n",
    "        adv_img = perturbation + x\n",
    "        adv_img = torch.clamp(adv_img, 0, 1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(adv_img)\n",
    "\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "    \n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector, perturb_norm/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "clamp = [0.0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    X, Y, norm = inference_n(data_loader, model, 'cuda', j) #0.001 -> 10\n",
    "\n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "\n",
    "    nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "    print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, label = \"line 1\", linestyle=\"-\")\n",
    "# plt.plot(y, x, label = \"line 2\", linestyle=\"--\")\n",
    "# plt.plot(x, np.sin(x), label = \"curve 1\", linestyle=\"-.\")\n",
    "# plt.plot(x, np.cos(x), label = \"curve 2\", linestyle=\":\")\n",
    "\n",
    "plt.plot(norm_l, nmi_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(norm_l, ari_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(norm_l, acc_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Perturbation Norm\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.savefig('cc_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same eval metrics across all codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_cus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "class_names = ('plane', 'car', 'bird', 'cat',\n",
    "       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "clamp = [0.0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    X, Y, norm = inference_n(data_loader, model, 'cuda', j)\n",
    "    Y = torch.from_numpy(Y).cuda()    \n",
    "    X = torch.from_numpy(X).cuda()\n",
    "    \n",
    "    clustering_stats_adv = eval_cus.check(Y, X, 10, class_names, compute_confusion_matrix=True, confusion_matrix_file=None)\n",
    "    acc = clustering_stats_adv['ACC']\n",
    "    nmi = clustering_stats_adv['NMI']\n",
    "    ari = clustering_stats_adv['ARI']\n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "\n",
    "#     nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "class_names = ('plane', 'car', 'bird', 'cat',\n",
    "       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "# clamp = [0.0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4]\n",
    "clamp = [0.03]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    X, Y, norm = inference_n(data_loader, model, 'cuda', j)\n",
    "    Y = torch.from_numpy(Y).cuda()    \n",
    "    X = torch.from_numpy(X).cuda()\n",
    "    \n",
    "    clustering_stats_adv = eval_cus.check(Y, X, 10, class_names, compute_confusion_matrix=True, confusion_matrix_file=None)\n",
    "    acc = clustering_stats_adv['ACC']\n",
    "    nmi = clustering_stats_adv['NMI']\n",
    "    ari = clustering_stats_adv['ARI']\n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "\n",
    "#     nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs:\n",
    "import eval_cus\n",
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMI_l = []\n",
    "ARI_l = []\n",
    "ACC_l = []\n",
    "Epo = []\n",
    "norm_l = [] \n",
    "class_names = ('airplane', 'car', 'bird', 'cat',\n",
    "       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "for epo in range(10,91, 10):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    pretrained_generator_path = f'./models/netG_cc_test_cifar-10_epoch_{epo}.pth'\n",
    "    pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "    pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "    pretrained_G.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    X, Y, norm = inference_n(data_loader, model, 'cuda', 0.03)\n",
    "    \n",
    "    del pretrained_G\n",
    "    Y = torch.from_numpy(Y).cuda()    \n",
    "    X = torch.from_numpy(X).cuda()\n",
    "    \n",
    "    clustering_stats_adv = eval_cus.check(Y, X, 10, class_names, compute_confusion_matrix=True, confusion_matrix_file=None)\n",
    "    acc = clustering_stats_adv['ACC']\n",
    "    nmi = clustering_stats_adv['NMI']\n",
    "    ari = clustering_stats_adv['ARI']\n",
    "    print(f'clamp {epo} avg norm: {norm}')\n",
    "\n",
    "#     nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc))\n",
    "    \n",
    "    norm_l.append(norm)\n",
    "    NMI_l.append(nmi)\n",
    "    ARI_l.append(ari)\n",
    "    ACC_l.append(acc)\n",
    "    Epo.append(epo*468) #468 queries in one epoch.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NMI_l)\n",
    "print(ARI_l)\n",
    "print(ACC_l)\n",
    "print(Epo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Epo, NMI_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(Epo, ARI_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(Epo, ACC_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Queries\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('scan_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Epo, norm_l, label = \"norm\", linestyle=\"-\")\n",
    "plt.xlabel(\"Queries\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('scan_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_cus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clamp = [0.0, 0.03, 1]\n",
    "print(clamp)\n",
    "class_names = ('airplane', 'car', 'bird', 'cat',\n",
    "       'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    X, Y, norm = inference_n(data_loader, model, 'cuda', j)\n",
    "    Y = torch.from_numpy(Y).cuda()    \n",
    "    X = torch.from_numpy(X).cuda()\n",
    "    \n",
    "    clustering_stats_adv = eval_cus.check(Y, X, 10, class_names, confusion_matrix_file=None, cf20=False, output_file2=f'CC_c10_{j}_n{norm}.pdf')\n",
    "    acc = clustering_stats_adv['ACC']\n",
    "    nmi = clustering_stats_adv['NMI']\n",
    "    ari = clustering_stats_adv['ARI']\n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "\n",
    "#     nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc))\n",
    "    print(norm)\n",
    "#     nmi_l.append(nmi)\n",
    "#     ari_l.append(ari)\n",
    "#     acc_l.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
