{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original CC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CIFAR-100\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from modules import resnet, network, transform\n",
    "from evaluation import evaluation\n",
    "from torch.utils import data\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, model, device):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(x)\n",
    "        c = c.detach()\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args\n",
    "# general\n",
    "seed= 42\n",
    "workers= 1\n",
    "dataset_dir= \"./dataset\"\n",
    "\n",
    "# train options\n",
    "batch_size= 256\n",
    "image_size= 224\n",
    "start_epoch= 0\n",
    "epoch= 1000\n",
    "dataset= \"CIFAR-100\" # CIFAR-10 / CIFAR-100 / STL-10 / ImageNet-10 / ImageNet-dogs / tiny-ImageNet\n",
    "\n",
    "# model options\n",
    "# resnet= \"ResNet34\" # ResNet18 / ResNet34 / ResNet50\n",
    "feature_dim= 128\n",
    "model_path= \"save/CIFAR-100\"\n",
    "reload= False\n",
    "\n",
    "# loss options\n",
    "learning_rate= 0.0003\n",
    "\n",
    "weight_decay= 0.\n",
    "instance_temperature= 0.5\n",
    "cluster_temperature= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "train_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./dataset',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=image_size).test_transform,\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./dataset',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=image_size).test_transform,\n",
    ")\n",
    "dataset = data.ConcatDataset([train_dataset, test_dataset])\n",
    "class_num = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=workers,\n",
    "    )\n",
    "\n",
    "#     data_loader = torch.utils.data.DataLoader(\n",
    "#         dataset,\n",
    "#         batch_size=args.batch_size,\n",
    "#         shuffle=True,\n",
    "#         drop_last=True,\n",
    "#         num_workers=args.workers,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place original cc model here\n",
    "cc_model = \"./models/cif_100_chec_1000.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = resnet.get_resnet(\"ResNet34\")\n",
    "model = network.Network(res, feature_dim, class_num)\n",
    "# model_fp = os.path.join(model_path, \"checkpoint_{}.tar\".format(start_epoch))\n",
    "model.load_state_dict(torch.load(cc_model, map_location=device.type)['net'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Creating features from model ###\")\n",
    "X, Y = inference(data_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dataset == \"CIFAR-100\":  # super-class\n",
    "super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "]\n",
    "Y_copy = copy.copy(Y)\n",
    "for i in range(20):\n",
    "    for j in super_label[i]:\n",
    "        Y[Y_copy == j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmi, ari, f, acc = evaluation.evaluate(Y, X) #Y = Label, X = pred\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_attack import GAN_Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "image_nc=3\n",
    "epochs = 60\n",
    "batch_size = 128\n",
    "BOX_MIN = 0\n",
    "BOX_MAX = 1\n",
    "model_num_labels = 10\n",
    "# print(dataset == \"CIFAR-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = GAN_Attack(device, model, model_num_labels, image_nc, BOX_MIN, BOX_MAX, \"CIFAR-100\")\n",
    "# model.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./dataset',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=224, s=0.5),\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./dataset',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=224, s=0.5),\n",
    ")\n",
    "dataset = data.ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "class_num = 20\n",
    "data_loader2 = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GAN.train(data_loader2, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original NMI, ARI, F, and ACC.\n",
    "X, Y = inference(data_loader, model, 'cuda')\n",
    "\n",
    " # super-class\n",
    "super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "]\n",
    "Y_copy = copy.copy(Y)\n",
    "for i in range(20):\n",
    "    for j in super_label[i]:\n",
    "        Y[Y_copy == j] = i\n",
    "            \n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = './models/netG_cc_CIFAR-100_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(images, labels):\n",
    "    print(type(images[0]), type(labels))\n",
    "    print(images.shape)\n",
    "    w = 10\n",
    "    h = 10\n",
    "    fig = plt.figure(figsize=(10, 20))\n",
    "    columns = 11\n",
    "    rows = 12\n",
    "    for i in range(10):\n",
    "#         img = np.random.randint(10, size=(h,w))\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "#         img = images[i] / 2 + 0.5   # unnormalize\n",
    "        img = images[i]\n",
    "        npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        \n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "#         plt.imshow(npimg.astype('uint8'))\n",
    "#   plt.show()\n",
    "#         plt.imshow(np.transpose(np.reshape(images[i].detach().cpu(), (3, 32,32)), (1,2,0)))\n",
    "        plt.title('#{}: {}'.format(i, labels[i]))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "def inference2(loader, model, device, pretrained_G):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j = 1\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        x = x.to(device)\n",
    "        perturbation = pretrained_G(x)\n",
    "        perturbation = torch.clamp(perturbation, -0.05, 0.05)\n",
    "        adv_img = perturbation + x\n",
    "        adv_img = torch.clamp(adv_img, 0, 1)\n",
    "        if j:\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            plot_examples(x,y)\n",
    "            torch.cuda.empty_cache()\n",
    "            plot_examples(adv_img, y)\n",
    "            j = 0\n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(adv_img)\n",
    "        c = c.detach()\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_imgs =  3000\n",
    "def save_examples(images, labels, noise=False, bno=0, adv=False, orig=False):\n",
    "    print(type(images[0]), type(labels))\n",
    "    global count_imgs\n",
    "    \n",
    "    super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "    ]\n",
    "    labels_copy = copy.copy(labels)\n",
    "    for i in range(20):\n",
    "        for j in super_label[i]:\n",
    "            labels[labels_copy == j] = i\n",
    "    \n",
    "    if count_imgs <=0 :\n",
    "        return\n",
    "    for i in range(min(len(images), 20)):\n",
    "        img = images[i]\n",
    "        npimg = img.cpu().detach().numpy()   # convert from tensor\n",
    "        npimg = np.clip(npimg, 0, 1)\n",
    "        count_imgs -= 1\n",
    "        if orig:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/C100/CC/orig/CC_c100_b{bno}_{i}_lab{labels[i]:02}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if adv:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/C100/CC/adv/CC_c100_b{bno}_{i}_lab{labels[i]:02}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if noise:\n",
    "            npimg = npimg / 2 + 0.5 \n",
    "            plt.imsave(f'Images/C100/CC/noise/CC_c100_b{bno}_{i}_noise_lab{labels[i]:02}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "def inference_save(loader, model, device, pretrained_G):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j = 1\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        x = x.to(device)\n",
    "        perturbation = pretrained_G(x)\n",
    "        perturbation = torch.clamp(perturbation, -0.05, 0.05)\n",
    "        adv_img = perturbation + x\n",
    "        adv_img = torch.clamp(adv_img, 0, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(adv_img)\n",
    "        c = c.detach()\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "        save_examples(x.cpu().detach(), y, bno=step, orig=True)\n",
    "        save_examples(adv_img.cpu().detach(), c.cpu().detach().numpy(), bno=step, adv=True)\n",
    "        save_examples(perturbation.cpu().detach(), c.cpu().detach().numpy(), bno=step, noise=True)\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, Y = inference_save(data_loader, model, 'cuda', pretrained_G)\n",
    "\n",
    "# super_label = [\n",
    "#     [72, 4, 95, 30, 55],\n",
    "#     [73, 32, 67, 91, 1],\n",
    "#     [92, 70, 82, 54, 62],\n",
    "#     [16, 61, 9, 10, 28],\n",
    "#     [51, 0, 53, 57, 83],\n",
    "#     [40, 39, 22, 87, 86],\n",
    "#     [20, 25, 94, 84, 5],\n",
    "#     [14, 24, 6, 7, 18],\n",
    "#     [43, 97, 42, 3, 88],\n",
    "#     [37, 17, 76, 12, 68],\n",
    "#     [49, 33, 71, 23, 60],\n",
    "#     [15, 21, 19, 31, 38],\n",
    "#     [75, 63, 66, 64, 34],\n",
    "#     [77, 26, 45, 99, 79],\n",
    "#     [11, 2, 35, 46, 98],\n",
    "#     [29, 93, 27, 78, 44],\n",
    "#     [65, 50, 74, 36, 80],\n",
    "#     [56, 52, 47, 59, 96],\n",
    "#     [8, 58, 90, 13, 48],\n",
    "#     [81, 69, 41, 89, 85],\n",
    "# ]\n",
    "# Y_copy = copy.copy(Y)\n",
    "# for i in range(20):\n",
    "#     for j in super_label[i]:\n",
    "#         Y[Y_copy == j] = i\n",
    "        \n",
    "# nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "# print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = inference2(data_loader, model, 'cuda', pretrained_G)\n",
    "\n",
    "super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "]\n",
    "Y_copy = copy.copy(Y)\n",
    "for i in range(20):\n",
    "    for j in super_label[i]:\n",
    "        Y[Y_copy == j] = i\n",
    "        \n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_MICE_CIFAR20_epoch200.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', pretrained_G)\n",
    "\n",
    "super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "]\n",
    "Y_copy = copy.copy(Y)\n",
    "for i in range(20):\n",
    "    for j in super_label[i]:\n",
    "        Y[Y_copy == j] = i\n",
    "        \n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base NNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_NNM_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', pretrained_G)\n",
    "\n",
    "super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "]\n",
    "Y_copy = copy.copy(Y)\n",
    "for i in range(20):\n",
    "    for j in super_label[i]:\n",
    "        Y[Y_copy == j] = i\n",
    "        \n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base RUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_RUC_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', pretrained_G)\n",
    "\n",
    "super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "]\n",
    "Y_copy = copy.copy(Y)\n",
    "for i in range(20):\n",
    "    for j in super_label[i]:\n",
    "        Y[Y_copy == j] = i\n",
    "        \n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base SCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_SCAN_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', pretrained_G)\n",
    "\n",
    "super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "]\n",
    "Y_copy = copy.copy(Y)\n",
    "for i in range(20):\n",
    "    for j in super_label[i]:\n",
    "        Y[Y_copy == j] = i\n",
    "        \n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_SPICE_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', pretrained_G)\n",
    "\n",
    "super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "]\n",
    "Y_copy = copy.copy(Y)\n",
    "for i in range(20):\n",
    "    for j in super_label[i]:\n",
    "        Y[Y_copy == j] = i\n",
    "        \n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original model again\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/CIFAR100/netG_cc_CIFAR20.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "def inference_per(loader, model, device, pretrained_G, clamp=0.05):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j = 1\n",
    "    perturb_norm = 0.0\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        x = x.to(device)\n",
    "        perturbation = pretrained_G(x)\n",
    "        perturbation = torch.clamp(perturbation, -clamp, clamp)\n",
    "        perturb_norm += torch.mean(torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1)).to('cpu').item()\n",
    "\n",
    "        adv_img = perturbation + x\n",
    "#         adv_img = torch.clamp(adv_img, 0, 1)\n",
    "        if j:\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "#             plot_examples(x,y)\n",
    "            torch.cuda.empty_cache()\n",
    "#             plot_examples(adv_img, y)\n",
    "            j = 0\n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(adv_img)\n",
    "        c = c.detach()\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "#         if step % 20 == 0:\n",
    "#             print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector, perturb_norm/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_label = [\n",
    "    [72, 4, 95, 30, 55],\n",
    "    [73, 32, 67, 91, 1],\n",
    "    [92, 70, 82, 54, 62],\n",
    "    [16, 61, 9, 10, 28],\n",
    "    [51, 0, 53, 57, 83],\n",
    "    [40, 39, 22, 87, 86],\n",
    "    [20, 25, 94, 84, 5],\n",
    "    [14, 24, 6, 7, 18],\n",
    "    [43, 97, 42, 3, 88],\n",
    "    [37, 17, 76, 12, 68],\n",
    "    [49, 33, 71, 23, 60],\n",
    "    [15, 21, 19, 31, 38],\n",
    "    [75, 63, 66, 64, 34],\n",
    "    [77, 26, 45, 99, 79],\n",
    "    [11, 2, 35, 46, 98],\n",
    "    [29, 93, 27, 78, 44],\n",
    "    [65, 50, 74, 36, 80],\n",
    "    [56, 52, 47, 59, 96],\n",
    "    [8, 58, 90, 13, 48],\n",
    "    [81, 69, 41, 89, 85],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiemnts for different clampings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "\n",
    "clamp = [0.0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    X, Y, norm = inference_per(data_loader, model, 'cuda', pretrained_G, j)\n",
    "    Y_copy = copy.copy(Y)\n",
    "    for i in range(20):\n",
    "        for j in super_label[i]:\n",
    "            Y[Y_copy == j] = i\n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "\n",
    "    nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "    print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, label = \"line 1\", linestyle=\"-\")\n",
    "# plt.plot(y, x, label = \"line 2\", linestyle=\"--\")\n",
    "# plt.plot(x, np.sin(x), label = \"curve 1\", linestyle=\"-.\")\n",
    "# plt.plot(x, np.cos(x), label = \"curve 2\", linestyle=\":\")\n",
    "\n",
    "plt.plot(norm_l, nmi_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(norm_l, ari_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(norm_l, acc_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Perturbation Norm\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.savefig('cc_cifar100.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "import eval_cus\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "# clamp = [0.0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4]\n",
    "clamp = [0, 0.05, 1]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    X, Y, norm = inference_per(data_loader, model, 'cuda', pretrained_G, j)\n",
    "    Y_copy = copy.copy(Y)\n",
    "    for i in range(20):\n",
    "        for j in super_label[i]:\n",
    "            Y[Y_copy == j] = i\n",
    "            \n",
    "    \n",
    "    Y = torch.from_numpy(Y).cuda()    \n",
    "    X = torch.from_numpy(X).cuda()\n",
    "    class_names = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "    clustering_stats_adv = eval_cus.check(Y, X, 20, class_names, compute_confusion_matrix=True, confusion_matrix_file=None, cf20=True, output_file2=f'CC_C100_{j}_n{norm}.pdf')\n",
    "    acc = clustering_stats_adv['ACC']\n",
    "    nmi = clustering_stats_adv['NMI']\n",
    "    ari = clustering_stats_adv['ARI']\n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "\n",
    "#     nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
