{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STL-10\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from modules import resnet, network, transform\n",
    "from evaluation import evaluation\n",
    "from torch.utils import data\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, model, device):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(x)\n",
    "        c = c.detach()\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args\n",
    "# general\n",
    "seed= 42\n",
    "workers= 1\n",
    "dataset_dir= \"./dataset\"\n",
    "\n",
    "# train options\n",
    "batch_size= 256\n",
    "image_size= 224\n",
    "start_epoch= 0\n",
    "epoch= 1000\n",
    "dataset= \"STL-10\" # CIFAR-10 / CIFAR-100 / STL-10 / ImageNet-10 / ImageNet-dogs / tiny-ImageNet\n",
    "\n",
    "# model options\n",
    "# resnet= \"ResNet34\" # ResNet18 / ResNet34 / ResNet50\n",
    "feature_dim= 128\n",
    "model_path= \"save/STL-10\"\n",
    "reload= False\n",
    "\n",
    "# loss options\n",
    "learning_rate= 0.0003\n",
    "weight_decay= 0.\n",
    "instance_temperature= 0.5\n",
    "cluster_temperature= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "train_dataset = torchvision.datasets.STL10(\n",
    "    root='./dataset',\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=image_size).test_transform,\n",
    ")\n",
    "test_dataset = torchvision.datasets.STL10(\n",
    "    root='./dataset',\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=image_size).test_transform,\n",
    ")\n",
    "dataset = data.ConcatDataset([train_dataset, test_dataset])\n",
    "class_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=workers,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place original CC model; here\n",
    "cc_model = \"./models/cif_stl_chec_1000.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = resnet.get_resnet(\"ResNet34\")\n",
    "model = network.Network(res, feature_dim, class_num)\n",
    "# model_fp = os.path.join(model_path, \"checkpoint_{}.tar\".format(start_epoch))\n",
    "model.load_state_dict(torch.load(cc_model, map_location=device.type)['net'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Creating features from model ###\")\n",
    "X, Y = inference(data_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmi, ari, f, acc = evaluation.evaluate(Y, X) #Y = Label, X = pred\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_attack import GAN_Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "image_nc=3\n",
    "epochs = 60\n",
    "batch_size = 128\n",
    "BOX_MIN = 0\n",
    "BOX_MAX = 1\n",
    "model_num_labels = 10\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = GAN_Attack(device, model, model_num_labels, image_nc, BOX_MIN, BOX_MAX, \"STL-10\")\n",
    "# model.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_dataset = torchvision.datasets.STL10(\n",
    "    root='./dataset',\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=image_size, s=0.5),\n",
    ")\n",
    "test_dataset = torchvision.datasets.STL10(\n",
    "    root='./dataset',\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=transform.Transforms(size=image_size, s = 0.5),\n",
    ")\n",
    "\n",
    "dataset = data.ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "class_num = 10\n",
    "data_loader2 = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "advGAN.train(data_loader2, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = './models/netG_cc_STL-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(images, labels):\n",
    "    print(type(images[0]), type(labels))\n",
    "    print(images.shape)\n",
    "    w = 10\n",
    "    h = 10\n",
    "    fig = plt.figure(figsize=(10, 20))\n",
    "    columns = 11\n",
    "    rows = 12\n",
    "    for i in range(10):\n",
    "#         img = np.random.randint(10, size=(h,w))\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "#         img = images[i] / 2 + 0.5   # unnormalize\n",
    "        img = images[i]\n",
    "        npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        \n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "#         plt.imshow(npimg.astype('uint8'))\n",
    "#   plt.show()\n",
    "\n",
    "#         plt.imshow(np.transpose(np.reshape(images[i].detach().cpu(), (3, 32,32)), (1,2,0)))\n",
    "        plt.title('#{}: {}'.format(i, labels[i]))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "def inference2(loader, model, device, clamp=0.03):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j = 1\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        x = x.to(device)\n",
    "        perturbation = pretrained_G(x)\n",
    "        perturbation = torch.clamp(perturbation, -clamp, clamp)\n",
    "        adv_img = perturbation + x\n",
    "        adv_img = torch.clamp(adv_img, 0, 1)\n",
    "        if j:\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            plot_examples(x,y)\n",
    "            torch.cuda.empty_cache()\n",
    "            plot_examples(adv_img, y)\n",
    "            j = 0\n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(adv_img)\n",
    "        c = c.detach()\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_imgs =  1000\n",
    "def save_examples(images, labels, noise=False, bno=0, adv=False, orig=False):\n",
    "    print(type(images[0]), type(labels))\n",
    "    global count_imgs\n",
    "    \n",
    "    if count_imgs <=0 :\n",
    "        return\n",
    "    for i in range(min(len(images), 20)):\n",
    "        img = images[i]\n",
    "        npimg = img.cpu().detach().numpy()   # convert from tensor\n",
    "        npimg = np.clip(npimg, 0, 1)\n",
    "        count_imgs -= 1\n",
    "        if orig:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/S10/CC/orig/CC_s10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if adv:\n",
    "#             npimg = np.transpose(npimg, (1, 2, 0))\n",
    "            plt.imsave(f'Images/S10/CC/adv/CC_s10_b{bno}_{i}_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "        if noise:\n",
    "            npimg = npimg / 2 + 0.5 \n",
    "            plt.imsave(f'Images/S10/CC/noise/CC_s10_b{bno}_{i}_noise_lab{labels[i]}.png', npimg.T, dpi=600)\n",
    "            continue\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "def inference_save(loader, model, device, pretrained_G):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j = 1\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        x = x.to(device)\n",
    "        perturbation = pretrained_G(x)\n",
    "        perturbation = torch.clamp(perturbation, -0.1, 0.1)\n",
    "        adv_img = perturbation + x\n",
    "        adv_img = torch.clamp(adv_img, 0, 1)\n",
    "#         if j:\n",
    "#             torch.cuda.empty_cache()\n",
    "            \n",
    "#             plot_examples(x,y)\n",
    "#             torch.cuda.empty_cache()\n",
    "#             plot_examples(adv_img, y)\n",
    "#             j = 0\n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(adv_img)\n",
    "        c = c.detach()\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "        save_examples(x, y, bno=step, orig=True)\n",
    "        save_examples(adv_img, c.cpu().detach().numpy(), bno=step, adv=True)\n",
    "        save_examples(perturbation, c.cpu().detach().numpy(), bno=step, noise=True)\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save samples\n",
    "# inference_save(data_loader, model, 'cuda', pretrained_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = inference2(data_loader, model, 'cuda', clamp=0.1)\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "\n",
    "# x = normalized_img * STD[:, None, None] + MEAN[:, None, None]\n",
    "\n",
    "def pp(images, labels):\n",
    "    print(type(images[0]), type(labels))\n",
    "    print(images.shape)\n",
    "#     w = \n",
    "#     h = 10\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    columns = 11\n",
    "    rows = 12\n",
    "    for i in range(35):\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        img = images[i]\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5   # unnormalize\n",
    "#         img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "#         img = (img * 255).astype(np.uint8)\n",
    "#         img = img / 2 + 0.5\n",
    "#         img = img / 2 + 0.5 \n",
    "#         npimg = img.detach().cpu().numpy()   # convert from tensor\n",
    "        \n",
    "#         plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "        plt.imshow(img.transpose(1, 2, 0))\n",
    "#         plt.imshow(npimg)\n",
    "#         plt.title('#{}: {}'.format(i, labels[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/STL10/netG_MICE_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', 0.4)\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base NNM\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/STL10/netG_NNM_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', 0.02)\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base SCAN\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/STL10/netG_SCAN_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', 0.05)\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base RUC\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/STL10/netG_RUC_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', 0.05)\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base SPICE\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = '../Generator_Models/STL10/netG_SPICE_stl10.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "X, Y = inference2(data_loader, model, 'cuda', 0.05)\n",
    "nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "def inference_n(loader, model, device, clamp=0.05):\n",
    "    model.eval()\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    j = 1\n",
    "    perturb_norm = 0.0\n",
    "#     p_n = []\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        x = x.to(device)\n",
    "        perturbation = pretrained_G(x)\n",
    "        perturbation = torch.clamp(perturbation, -clamp, clamp)\n",
    "        perturb_norm += torch.mean(torch.norm(perturbation.view(perturbation.shape[0], -1), 2, dim=1)).to('cpu').item()\n",
    "        \n",
    "        \n",
    "        adv_img = perturbation + x\n",
    "        adv_img = torch.clamp(adv_img, 0, 1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            c = model.forward_cluster(adv_img)\n",
    "\n",
    "        feature_vector.extend(c.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "    \n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector, perturb_norm/len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra experiements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original Model\n",
    "\n",
    "import models_clu\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "pretrained_generator_path = './models/netG_cc_STL-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "clamp = [0.0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    X, Y, norm = inference_n(data_loader, model, 'cuda', j) #0.001 -> 10\n",
    "\n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "\n",
    "    nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "    print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x, y, label = \"line 1\", linestyle=\"-\")\n",
    "# plt.plot(y, x, label = \"line 2\", linestyle=\"--\")\n",
    "# plt.plot(x, np.sin(x), label = \"curve 1\", linestyle=\"-.\")\n",
    "# plt.plot(x, np.cos(x), label = \"curve 2\", linestyle=\":\")\n",
    "\n",
    "plt.plot(norm_l, nmi_l, label = \"nmi\", linestyle=\"-\")\n",
    "plt.plot(norm_l, ari_l, label = \"ari\", linestyle=\"-\")\n",
    "plt.plot(norm_l, acc_l, label = \"acc\", linestyle=\"-\")\n",
    "plt.xlabel(\"Perturbation Norm\")\n",
    "plt.ylabel(\"Performace\")\n",
    "plt.legend()\n",
    "plt.savefig('cc_cifar10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same acc form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_cus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial NMI, ARI, F, and ACC\n",
    "\n",
    "import models_clu\n",
    "import eval_cus\n",
    "use_cuda=True\n",
    "image_nc=3\n",
    "batch_size = 128\n",
    "\n",
    "gen_input_nc = image_nc\n",
    "# load the generator of adversarial examples\n",
    "# pretrained_generator_path = './models/netG_cc_epoch_120.pth'\n",
    "pretrained_generator_path = './models/netG_cc_cifar-10_epoch_120.pth'\n",
    "pretrained_G = models_clu.Generator(gen_input_nc, image_nc).to(device)\n",
    "pretrained_G.load_state_dict(torch.load(pretrained_generator_path))\n",
    "pretrained_G.eval()\n",
    "\n",
    "norm_l = []\n",
    "nmi_l = []\n",
    "ari_l = []\n",
    "acc_l = []\n",
    "# clamp = [j for j in range(0, 1, 0.02)]\n",
    "# clamp = [j for j in np.arange(0, 1.05, 0.05)]\n",
    "# clamp = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "# clamp = [0.0, 0.001, 0.003, 0.005, 0.007, 0.01, 0.015, 0.02, 0.025, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4]\n",
    "clamp = [0, 0.03, 1]\n",
    "print(clamp)\n",
    "\n",
    "for j in clamp:\n",
    "    torch.cuda.empty_cache()\n",
    "    X, Y, norm = inference_n(data_loader, model, 'cuda', j)\n",
    "    print(norm)\n",
    "    \n",
    "    Y = torch.from_numpy(Y).cuda()    \n",
    "    X = torch.from_numpy(X).cuda()\n",
    "    class_names =  ['airplane',\n",
    "                 'bird',\n",
    "                 'car',\n",
    "                 'cat',\n",
    "                 'deer',\n",
    "                 'dog',\n",
    "                 'horse',\n",
    "                 'monkey',\n",
    "                 'ship',\n",
    "                 'truck']\n",
    "    clustering_stats_adv = eval_cus.check(Y, X, 10, class_names, compute_confusion_matrix=True, confusion_matrix_file=None, output_file2=f\"CC_s10_{j}_{norm}.pdf\")\n",
    "    acc = clustering_stats_adv['ACC']\n",
    "    nmi = clustering_stats_adv['NMI']\n",
    "    ari = clustering_stats_adv['ARI']\n",
    "    print(f'clamp {j} avg norm: {norm}')\n",
    "\n",
    "#     nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "    print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc))\n",
    "    norm_l.append(norm)\n",
    "    nmi_l.append(nmi)\n",
    "    ari_l.append(ari)\n",
    "    acc_l.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_cus\n",
    "import importlib\n",
    "importlib.reload(eval_cus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names =  ['airplane',\n",
    "             'bird',\n",
    "             'car',\n",
    "             'cat',\n",
    "             'deer',\n",
    "             'dog',\n",
    "             'horse',\n",
    "             'monkey',\n",
    "             'ship',\n",
    "             'truck']\n",
    "X, Y, norm = inference_n(data_loader, model, 'cuda', 0)\n",
    "print(norm)\n",
    "\n",
    "Y = torch.from_numpy(Y).cuda()    \n",
    "X = torch.from_numpy(X).cuda()\n",
    "clustering_stats_adv = eval_cus.check(Y, X, 10, class_names, compute_confusion_matrix=True, output_file2= 'cc_0.1_orig.pdf')\n",
    "\n",
    "acc = clustering_stats_adv['ACC']\n",
    "nmi = clustering_stats_adv['NMI']\n",
    "ari = clustering_stats_adv['ARI']\n",
    "print(f'clamp 0.03, avg norm: {norm}')\n",
    "\n",
    "#     nmi, ari, f, acc = evaluation.evaluate(Y, X)\n",
    "print('NMI = {:.4f} ARI = {:.4f} ACC = {:.4f}'.format(nmi, ari, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_l)\n",
    "print()\n",
    "print(nmi_l)\n",
    "print()\n",
    "print(ari_l)\n",
    "print()\n",
    "print(acc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
